[{"content":"Automated Whitebox Fuzz Testing\n0. Abstract fuzz testing은 소프트웨어 보안 취약점을 찾는 효과적인 기술이다. 전통적인 fuzzer들은 well-formed input에 random mutations을 적용하고 결과값을 테스트한다. 이 논문에서는 Symbolic execution과 Dynamic test generation을 적용하여 alternative whitebox fuzz testing을 구현하였다.\n이 논문에서는 well-formed input에 따라 실제로 실행되는 것을 기록하고, symbolicaly evalution하고, 프로그램이 입력을 어떻게 사용하는지 확인하여 입력에 대한 제약조건을 수집한다. 수집한 제약조건들을 하나씩 부정하고 constraint solver를 이용하여 solve한다. 이를 통해 프로그램에서 다른 경로를 실행하는 새로운 input을 생성한다. 이러한 과정은 code-coverage maximizing heuristic의 도움으로 반복된다.\n이 알고리즘을 SAGE(Scalable, Automated, Guided, Execution)이라는 새로운 도구에서 구현하였고 SAGE는 임의의 파일을 읽는 windows application을 x86 instruct level tracing, emulation할 수 있는 white box fuzzing tool이다. 대규모 입력 파일과 수백만개의 명령으로 구성된 긴 실행 추적을 통하여 dynamic test generation을 하는 과정속 적용된 주요 최적화 기법을 소개한다.\n이후 여러 windows application을 대상으로한 실험을 소개한다. 특정 지식없이 SAGE는 black box fuzzing, static analysis tool이 놓친 MS07-017 ANI vulnerability를 찾았고 image processsors, media players, file decoders등에서 30개 이상의 새로운 버그를 발견하였다. 이중 몇가지는 memory access violation이다.\n1. Introduction \u0026ldquo;Month of Browser Bugs\u0026quot;이 새로운 bug를 공개한 이후 fuzz testing은 large application에서 빠르고 효율적으로 보안 버그를 찾는 방법으로 떠오르고 있다. fuzz testing은 blackbox random testing의 한 사례이다. 어떤 경우에는 well-formed input을 생성하기위하여 grammar가 사용되며 application의 특정 지식과 test geuristics을 사용한다.\nfuzz testing은 효과적이지만 blackbox testing의 한계는 잘 알려져 있다.\n1 if (x==10) (statement) 의 경우 x가 무작위로 선택된 2^32분의 1 확률로 실행된다. 이것은 random testing이 낮은 code coverage를 제공하는 이유를 설명한다.\n이러한 한계는 버그가 포함된 코드가 실행되지 않았기 때문에 BOF와 같은 심각한 security bug를 놓칠 수 있음을 의미한다.\n이 논문에서 dynamic test generation으로부터 영감을 받아 whitebox testing 접근 방법을 제안한다.\n알고리즘은 fixed input으로 시작하여 프로그램을 symbolic하게 실행하며 조건문에서 constraint을 수집한다. 수집한 constraint을 부정하고 Constraint Solver를 이용하여 프로그램 내에서 다양한 path를 테스트 하는데 사용된다.\n이 과정은 새로운 search algorithm과 coverage-maximizing heuristic을 이용하여 반복된다.\n예를들어 x=0을 위의 코드로 실행되면 constraint x≠10이 생성된다. 이를 부정하여 x=10을 생성하고 주어진 조건문을 만족하는 새로운 입력을 제공한다.\n이를 통하여 입력 형식에 대한 구체적인 지식 없이도 보안 버그를 찾기 위해 프로그램의 추가 코드를 실행하고 테스트할 수 있다. 또한 프로그래머가 메모리를 올바르게 할당하고 버퍼를 조작하지 못하게 할 수 있는 \u0026ldquo;corner cases\u0026quot;를 자동으로 발견하고 테스트하여 security vulnerabilities를 탐지한다.\n이론적으로 systematic dynamic test generation은 full program path coverage, program verification에 도달할 수 있다. 그러나 실제로 테스트 대상 프로그램의 path의 수가 크고 symbolic exectuion, constraint generation, constraint solving이 부정확하기 때문에 일반적으로 search가 불가능하다.\n따라서 우리는 실용적인 절충안을 찾을 수 밖에 없으며 이 논문에서는 유용하다고 생각하는 점을 제시한다. 실제로 특정 접근 방식은 이전에 well-test되었던 large application에서 새로운 결함을 찾는데 효과적이다.\n우리의 알고리즘은 많은 결함을 찾아내었고 defact triage problem을 다룬다. 이는 static program analysis와 blackbox fuzzing에서 흔한 일이지만 dynamic test generation 에서는 이제까지 다루지 않았던 문제이다. 우리의 접근 방법은 기존 dynamic test generation에서 수행되었던것보다 더 큰 application을 테스트할 수 있다.\n이 접근방식을 SAGE에 구현하였다 SAGE는 Scalable, Automated, Guided Execution의 약자로 x84 Windows application을 위한 whole-program whitebox file fuzzing tool이다. 현재 도구는 file-reading application에 중점을 두고 있지만 natwork-facing application에 대해서도 적용 가능하다.\nSAGE는 blackbox fuzzer가 찾을 수 없었던 버그를 찾을 수 있다. 또한 formet-specific knowledge가 없이 blackbox fuzzing과 static anlysis에서 놓친 MS07-017 ANI bulnerability를 찾았다. 우리의 작엄은 다음 3가지에 대해 기여하였다.\n2장에서 search가 불완전 할 수 있는 large input file, long execution traces를 갖는 large applicationd에 대한 새로운 search algorithm을 제시하였다. 3장에서는 SAGE의 구현에 관하여 논의하였다. symbolic execution algorithm 뒤에있는 엔지니어링 선택과 수백만 명령어의 program traces로 확장할 수 있는 key optimization techniques을 설명한다. 4장은 SAGE를 사용한 경험에 대하여 설명하고 있다. 발견한 결함의 예를 들고 다양한 실험의 결과에 대해서 논의하였다. 2. A White Box Fuzzing Algorithm 2.1 Background: Dynamic Test Generation 다음 프로그램에서 논의해 보자\n1 2 3 4 5 6 7 8 void top (char input[4]){ int cnt=0; if (input[0]==\u0026#39;b\u0026#39;) cnt++; if (input[1]==\u0026#39;a\u0026#39;) cnt++; if (input[2]==\u0026#39;d\u0026#39;) cnt++; if (input[3]==\u0026#39;!\u0026#39;) cnt++;; if (cnt\u0026gt;=3) abort(); //error } abort가 발생할 조건을 random testing(blackbox fuzzing)으로 찾을 확률은 5/2^(8*4)정도이다. 이는 random testing의 전형적인 문제로 프로그램의 가능한 모든 execution path로 이끌어낼 input을 생성하기 어렵다.\n반면 whitebox dynamic test generation은 이 프로그램의 오류를 쉽게 찾을 수 있다. 일부 initial input을 통하여 프로그램을 실행하여 실행 도중 분기문에서의 족너으로부터 입력에 대한 제약을 수집하기 위해 dynamic symbolic execution을 수행하여 constraint solver를 통하여 이전의 입력에 변형을 주어 다음 실행의 새로운 branch를 찾도록 한다.\n이 과정은 주어진 프로그램 statement나 path가 실행되거나 프로그램의 모든(많은) 실행 가능한 path가 실행될때까지 반복된다.\n위의 예시를 가정하면 우리는 초기 4개의 문자열 good을 가지고 함수 top을 실행한다 (경로 ρ). Figure 2는 top에 대한 모든 실행 가능한 program path의 집합을 보여준다. 가장 왼쪽 경로는 \u0026lsquo;good\u0026rsquo;에 대한 프로그램의 첫번째 실행을 나타내며 프로그램 내의 모든 if문의 else에 해당하는 경로에 해당한다. leaf의 숫자들은 0은 cnt의 값을 나타내고 있다.\nnormal execution과 함께 symbolic execution은 조건문이 어떻게 평가되는지에 따라 다음과 같은 condition을 수집한다.\ni_0≠b, i_1≠a, i_2≠d, i_3≠! (i_0는 input[0]의 memory location의 값을 나타내는 symbolic variable) 다음 pathconstraint에 대해서 생각해보자\nφ_ρ = \u0026lt;i_0≠b, i_1≠a, i_2≠d, i_3≠!\u0026gt; 이는 input vector의 equivalant class이다. 즉, 방금 실행된 path로 실행되는 모든 input vector이다. 프로그램을 다른 equivalant class로 실행하려면 현제 path constraint 하나를 부정하여 다른 path로 실행할 수 있다.\nex) φ = \u0026lt;i_0≠b, i_1≠a, i_2≠d, i_3=!\u0026gt; 이 path constraint의 해는 goo! 이다. 이를 실행하게 된다면 Figure2에서 왼쪽에서 두번째에 있는 path가 실행 된다. 이과정을 반복함으로 이 프로그램에서 가능한 모든 16가지 path를 실행할 수 있다.\n이 탐색이 depth-first order로 실행된다면 Figure의 왼쪽에서 오른쪽으로 탐색된다. 그러면 cnt==3인 첫 오류는 8번째 실행에서 발생하고 9번째 실행 후에 full branch/block coverage에 도달한다.\n2.2 Limitations 위에서 간략하게 소개된 Systematic dynamic test generation에는 두가지 한계가 존재한다.\n2.2.1 Path explosion 모든 실행 가능한 path를 실행하는것은 실제 대규모 프로그램에 대해서 확장성이 없다. path explosion은 dynamic test generation 을 compositionally하게 수행하면서 완하할 수 있다.\n이는 함수를 독립적으로 테스팅하고 테스트 결과를 함수 입력전제조건과 출력 후 조건을 사용하여 function summaries하고 high-level function을 테스팅할때 이러한 summaries를 제사용 함으로서 이루어진다.\nsoftware testing에서 summaries가 유용해 보이지만 수백만 가지 명령어를 가진 large application에 대해서 full path coverage를 도달하기엔 한계가 존재한다.\n2.2.2 Imperfect symbolic execution large program에 대한 symbolic execution은 복잡한 program statements(포인터 조작, 산술연산 등)과 운영체제, 라이브러리 함수 호출로 인하여 정확하게 추론하기 어렵거나 불가능하여 정밀도가 떨어질 수 있다. 즉 합리적인 비용으로 정밀도를 가지고 symbolically precision하는것은 어렵다.\nsymbolic execution이 불가능할때 concrete한 값을 사용하여 constraint를 단순화 하고 단순화된 부분적 symbolic execution을 수행할 수 있다.\n주어진 input vector에 대한 symbolic execution으로 예측된 프로그램 path와 실제 실행된 path가 일치하지 않을때 divergence가 발생하였다고 한다.\ndivergence은 예측된 path를 bit vector(각 조건분기 결과에 대한 한 비트)로 기록하고 이후 실제로 해당 path가 수행되어있는지 확인함으로 감지할 수 있다.\n2.3 Generational Search 이러한 실용적 한계를 해결하기위하여 새로운 search algorithm을 소개한다. 이 알고리즘은 다음과 같은 주요 특징을 가지고 있다.\n대규모 입력(수천개의 symbolic variable)을 사용하고 매우 깊은 path(수백만개의 명렁어)를 가진 large application의 state space를 체계적이고 부분적으로 탐색하도록 설계되었다. search 과정에서 중복을 피하며 각 symbolic execution(long, expensive)에서 생성된 새로운 테스트의 수를 극대한다. 버그를 빠르게 찾는것을 목표로 가능한 빨리 code coverage를 극대화하기 위한 heuristic을 사용한다. divergence가 발생할때 recover할 수 있고 계속 진행된다. 이 새로운 search algorithm은 아래 두 코드로 제시된다. 먼저 Search함수는 standard한 과정이다.\n1. 초기 inputSeed를 workList에 넣는다. 2. 프로그램을 실행하여 bug가 감지되었는지 확인한다. 3. workList에서 Input 하나 선택하고 ExpandExecution을 통하여 새로운 childInputs을 생성한다. 4. childInput의 각각에 대해 프로그램을 실행하고 오류를 확인하고 점수를 계산한다. 5. workList에 이를 추가한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Search(inputSeed){ inputSeed.bound = 0; workList = {inputSeed}; Run\u0026amp;Check(inputSeed); while (workList not empty) {//new children input = PickFirstItem(workList); childInputs = ExpandExecution(input); while (childInputs not empty) { newInput = PickOneItem(childInputs); Run\u0026amp;Check(newInput); Score(newInput); workList = workList + newInput; } } } 이 알고리즘에서 주요한 부분은 아래코드와 같이 childInput을 확장하는 방식에 있다. ExpandExecution은 아래와 같이 동작한다.\n1. 해당 입력으로 symbolic excution를 통하여 path constraint (PC)를 생성한다. 2. not(PC[j])와 PC[0..(j-1)]이 해 I가 존재하는지 확인한다. 3. 해가 존재한다면 해를 이용하여 input을 업데이트한다. 4. 새로운 input은 evalutaion을 위하여 저장한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 ExpandExecution(input) { childInputs = {}; // symbolically execute (program,input) PC = ComputePathConstraint(input); for (j=input.bound; j \u0026lt; |PC|; j++){ if((PC[0..(j-1)] and not(PC[j]))has a solution I){ newInput = input + I; newInput.bound = j; childInputs = childInputs + newInput; } } return childInputs; } 즉 inputSeed와 PC로 시작하여 새로운 search alogrithm은 PC의 모든 constraint를 확장하려고 시도할것이다. DFS의 경우 마지막 constraint를, BFS의 경우 첫번째 constraint를 확장하는것과 대비된다.\n또한 child sub-search가 중복 탐색하는것을 방지하기위하여 bound 매개변수를 사용하여 sub-search가 parent로부터 시작된 분기로 돌아가는것을 제한한다.\n각 실행이 많은 child로 확장되기 때문에 이러한 검색 순서를 generational search 라고 한다.\n다시 top에 대해 고려해 본다면 초기 입력이 good이라고 가정하였을때 Figure 2의 tree에서 가장 왼쪽 path는 그 입력에 대한 첫번째 실행을 의미한다.\n이 parent execution에서 generational search는 4개의 first-generation child를 생성하는데 이는 leaf에 1로 기록된 4개의 path에 해당한다. 실제로 이 path들은 parent의 path constraint중 하나의 constraint를 부정하는것에 해당한다.\n위 코드의 과정을 통하여 6개의 second-generation child를 생성할 수 있다. 이 과정을 반복하여 top 함수의 모든 실행 가능한 execution path를 한번씩 생성할 수 있다. 또한 cnt의 값은 generation number을 나타낸다.\nExpandExecution은 현재 path constraint에서 하나만 확장하는 대신 bound 안의 모든 constraint를 확장하기 때문에 각 symbolic execution에서 생성된 새로운 테스트 input의 수를 극대화 한다.\n이 최적화는 top과 같은 작은 프로그램의 모든 execution path를 탐색하는데는 중요하지 않을 수 있지만 symbolic execution이 오랜 시간 걸리는 경우(모든 path를 실행하는것이 불가능한 large application)에는 중요하다. 3장에서 이에대해 더 자세히 논의되고 4장에서 관련된 실험을 통해 설명한다.\n이 시나리오에서 initial input으로 수행된 첫번째 symbolic execution을 최대한 이용하고 first-generation child를 체계적으로 탐색하고자 한다. 이검색 전략은 initial input이 잘 형성되어 있을때 가장 잘 작동한다.\n실제로 프로그램 코드의 더 많은 부분을 실행할 가능성이 더 높아지고 따라서 더 많은 constraint를 부어할 수 있으며 그 결과 더 많은 child가 생성된다. 이는 4장에서 실험을 통해 보여진다.\ninitial input에 대한 중요성은 전통적인 blackbox fuzz testing에서 수행하는것과 유사하며 이때문에 이러한 검색 기법을 whitebox fuzzing라고 한다.\n첫번째 parent execution의 child를 확장하는것은 빠르게 block covarage를 극대화 하는 heuristic를 사용하여 우선순위를 정하여 더 빠르게 더 많은 bug를 찾을 수 있다.\nSearch의 Score함수는 newInput을 실행하여 이전 모든 실행과 비교했을때 얻은 incremental block coverage를 계산한다.\n예를들어 100개의 새로운 block을 만드는 newInput에는 100점을 할당한다.\n이후 newInput은 점수에 따라 workList에 삽입되며 높은 점수를 가진 항목이 List의 가장 앞에 배치된다. 즉 모든 자식들은 generation number와 관련없이 서로 경쟁한다.\n우리의 block coverage heuristic은 EXE의 Best-First Search와 관련있다. 하지만 전체 검색 전략은 다르다. EXE는 block coverage heuristic을 사용하지만 다음 child 를 탐색할때 DFS를 사용하는 반면 우리는 generational serach를 사용하여 모든 child를 테스트한다. workList에서 가장 좋은 것을 선택하기 전에 점수를 부여한다.\nScore 함수로 계산된 block coverage heuristic은 divergent를 처리하는데도 도움이 된다. 하나의 divergent는 검색의 완전성을 손상하지만 매우 큰 검색 공간에서는 검색이 불완전할 수 밖에 없으므로 주요 문제가 되진 않는다. 하지만 divergent가 발생한다면 검색이 진행되지 않는다.\n예를 들어서 path P에서 이전 탐색된 경로 P\u0026rsquo;로 divergence하는 경우 DFS는 P\u0026rsquo;과 P사이에 영원히 순환한다. 반면 우리의 generational search는 dievergence를 허용하고 이러한 pathological 상황에서 회복할 수 있다.\n실제로 각 실행은 DFS처럼 많은 child를 생성하며, 만약 child P가 이전 실행 P\u0026rsquo;으로 divergent한다면 p는 점수가 0이되어 workList의 끝에 배치되므로 정상적인(non-divergent) child의 확장에 방해를 주지 않는다. 또한 divergence은 4장에서 다룰 우리의 알고리즘의 중요한 기능이다.\n마지막으로 generational search는 병렬화 하기 쉽다. child를 독립적으로 확인하고 점수를 부여할 수 있다.\n3. The SAGE System SAGE(Scalable, Automated, Guided Execution)은 파일에서 읽은 바이트를 symbolic input으로 취급하여 windows에서 실행되는 모든 파일 읽기 프로그램을 테스트할 수 있다.\nSAGE의 또 다른 혁신은 symbolic execution을 수행할때 x86 Binary level에서 trace할 수 있다는 것이다.\n이 섹션은 SGAE의 설계 선택을 정당화 할 수 있는 논리를 제시한다.\n3.1 System Architecture SAGE는 4가지 유형의 작업을 반복하며 generational serach를 수행한다.\n3.1.1 Tester Tester는 testinput으로 프로그램을 실행하여 access violation exceptions과 extreme memory consumption등 비정상적인 이벤트를 찾는 Run\u0026amp;Check를 구현한다. Tester가 오류를 감지하면 testcase를 저장하고 4장에 나오는 방법대로 분류를 수행한다.\n3.1.2 Tracer Tracer는 동힐한 input으로 다시 실행하여 프로그램이 실행되지 않을때 확인하기 위한 로그를 생성하고 저장한다. 이 작업은 iDNA framework를 사용하여 machine-instruction level에서의 execution traces를 수집한다.\n3.1.3 CoverageCollector 기록된 로그 재생하여 어떤 basic block이 실행되었는지 계산한다. SAGE는 이 정보를 사용하여 Score 함수를 구현한다.\n3.1.4 SymbolicExecutor 기록된 로그를 다시 재생하여 입력관련 constraint를 수집하고 constraint solver Disolver를 사용하여 새로운 입력을 생성하고 2.3절의 ExpandExecution을 구현한다.\n3.1.5 TrueScan CoverageCollector와 SymbolicExecutor는 iDNA에 의해 생성된 trace file을 사용하고 기록된 실행을 가상으로 재실행하는 trace replay framework TruScan위에 구축하였다.\nTruScan은 symbolic execution을 단순화 하는 다음과 같은 기능을 제공한다.\n명령어 디코딩 symbolic information에 대한 인터페이스 제공 다양한 입출력 시스템 호출 모니터링 heap, stack frame 할당 추적 프로그램 구조를 통한 data flow tracking 3.2 Trace-based x86 Constraint Generation SAGE의 constraint generation은 dynamical test generation과 두가지 방면에서 차이가 있다.\n3.2.1 Machine-Code-Based Approach Multitude of languages and build processes source-based 계측은 테스트 대상 프로그램에 사용된 특정 언어, 컴파일러, 빌드 프로세스를 지원해야한다. 따라서 새로운 언어, 컴파일러, 빌드 도구에 계측을 적용하는데는 많은 초기비용이 든다. 다양한 빌드 프로세스와 호환되지 않는 컴파일러 버전으로 개발된 많은 application을 cover하는 것은 쉽지 않다.\n반면 machine-code-based symbolic execution engine은 복잡하지만 아키텍처마다 한번만 구현하면 된다.\nCompiler and post-build transformations 실제로 출시된 binary code에서 symbolic execution을 수행함으로서 SAGE는 대상 프로그램 뿐만 아니라 컴파일, 후처리 과정에서 발생할 수 있는 버그를 포착할 수 있게 한다.\n예를들어 코드 난독화 도구나 base block transformer와 같은 도구는 source code와 bianary code사이으 미묘한 차이를 발생시킬 수 있다.\nUnavailability of source source code를 얻기 어려울 수 있다. source-based 계측은 self-modifying, JITed(Just-In-Time compiled) 코드에 대해서 어려울 수 있으나 SAGE는 machine code level에서 작업함으로 이러한 문제를 해결할 수 있다.\n물론 source code에는 machine code에서 즉시 보이지 않는 타입과 구조에 대한 정보가 있지만 SAGE의 path search에는 이 정보가 필요하지 않다.\n3.2.2 Offline Trace-Based Constraint Generation SAGE는 online 계측 대신 offline trace기반의 constraint generation을 사용한다. online generation은 프로그램이 실행될때 정적으로 주입된 계측 코드나 Nirvana, Valgrind와 같은 static binary 계측도구를 이용하여 constraint가 생성된다.\nSAGE가 offline trace-based constraint generation을 사용하는것은 두가지 이유 때문이다.\n프로그램은 OS에 의하여 보호되거나 난독화될 수 있는 binary 요소들을 포함할 수 있어 계측된 버전으로 교체하기 어려울 수 있다. 프로그램의 비결정성은 online constraint generation의 디버깅을 어렵게 만든다. constraint generation engine에 문제가 발생한다면 이를 재현하기 어려울 것이기 때문이다. SAGE에서 constraint generation은 실행시간 동안 모든 비결정적 이벤트의 결과를 기록하는 execution trace에서 작동하기에 완전히 결정론적이다. 3.3 Constraint Generation Symbolic Tag SAGE는 프로그램의 concrete and symbolic state를 각 메모리 위치와 레지스터를 byte-sized value와 symbolic tag를 각각 연결하여 한쌍으로 저장한다. symbolic tag는 input vlaue나 어떤 값의 함수를 나타내는 표현식이다.\nSAGE는 여러 종류의 tag를 지원한다.\ninput(m) input의 m번째 바이트 c : 상수 t1 op t2 : t1과 t2의 연산(op)값 sequence tag \u0026lt;t0\u0026hellip;tn\u0026gt; : t0\u0026hellip;tn에서 내는 byte-size값을 그룹화 하여 얻은 word, double-word 크기의 값 subtag (t,i) : word, double-word 크기의 t중 i번째 byte의 값 SAGE는 symbolic pointer dereference를 추론하지 않는다. SAGE는 비 상수 symbolic tag마다 새로운 symbolic variable을 정의한다. SAGE가 프로그램 trace를 재생할때 방문한 각 명령어의 의미에 따라 concrete and symbolic 저장소를 업데이트한다.\nSAGE는 symbolic tag propagation을 수행하는것 이외에도 input vlaue에 대한 constraint를 생성한다. constraint는 symbolic variable간의 관계를 나타낸다.\n예를 들어 input(4)에 해당하는 변수 x가 주어졌을때 x\u0026lt;10은 입력의 다섯번째 바이트가 10보다 크다는 뜻이다.\ninput에 의존하는 conditional jump를 만나면 분기의 결과를 모델링하는 constraint를 생성하고 지금까지 만난 contraint로 구성된 path constraint에 추가한다.\nTracking Symbolic Tag and Collecting Constraints 다음은 symbolic tag를 추적하고 constraint를 수집하는 과정을 보여준다.\n1 2 3 4 5 6 7 # read 10 byte file into a # buffer beginning at address 1000 mov ebx, 1005 mov al, byte [ebx] dec al # Decrement al jz LabelForIfZero # Jump if al == 0 10byte의 파일을 읽어서 1000번지 주소에 저장한다. 이 명령어를 실행함에 따라 SAGE는 주소 1000~1009를 symbolic tag input(0)~input(9)와 연결하여 symbolic 저장소를 업데이트한다. mov 명령어는 6번째 입력 바이트를 al레즈스터로 로드한다. 명령어를 재생한 후 SAGE는 al을 input(5)dp mapping하는것으로 symbolic 저장소를 업데이트한다. 마지막 두 명령언s al을 감소하고 감소된 값이 0이면 LabelForIfZero로 conditional jump를 수행한다. 분기의 결과에 따라 두가지 constraint중 하나를 추가한다. (t=input(5)-1 -\u0026gt; t=0 or t=1 추가) Conditional Jump 이는 x86 machine instruction 으로부터 constraint를 형성하는데 있어서 주요 문제중 하나로 이어진다. conditional expression에서 비교과 이루어질때 그것이 어떻게 conditional jump에 사용되는지 알 수 없다.\nEFLAG 프로세서에는 CF,SF,AF,PF,OF,ZF와 같은 EFLAG가 존재한다. EFLAG는 다양한 명령어의 결과에 따라 결정된다 예를들어 CF는 산술연산간 carry가 발생하였다면 1로 설정된다.\nEFLAG의 처리를 위해 SAGE는 n비트의 값으로 f0\u0026hellip;fn-1에 따라 설정된 비트를 나타네는 bit vector tag \u0026lt;f0\u0026hellip;fn-1\u0026gt;을 정의한다.\n위의 예시에서 SGAE가 dec명령어를 실행할떄 al과 EFLAG에 대한 symbolic 저장소의 mapping을 업데이트 한다(t=input(5)-1, CF,ZF).\nCasting x86에서 자자주 사용되는 관행은 byte, word, double word간의 casting이다. 테스트 대상 프로그램의 코드에 명시적인 casting이 포함되지 않더라도 atol, malloc, memcpy등 run-time library에서 casting을 수행하는 함수를 호출하게 된다.\nSAGE는 subtag와 sequence tag를 이용하여 casting의 정확한 처리를 구현한다.\n1 2 3 mov ch, byte [...] mov cl, byte [...] inc cx # Increment cx 두개의 명령어가 symbolic tag t1,t2와 관련된 주소를 읽을때 SAGE가 명령어를 재생할때 symbolic 저장소는 cl-\u0026gt;t1, ch-\u0026gt;t2으로 mapping을 업데이트한다. 다음 명령어는 cx를 증가한다 cx는 16bit 레지스터로 cl과 ch를 포함한다.\n증가하기 전에 cx의 내용은 \u0026lt;t1,t2\u0026gt;로 표현할 수 있다. 증가한 후 cx는 t=\u0026lt;t1,t2+1\u0026gt;로 표현할 수 있는데 inc를 마무리하기 위하여 SAGE는 symbolic 저장소의 byte크기의 maaping을 cl-\u0026gt;subtag(t,0), ch-\u0026gt;subtag(t,1)로 업데이트 한다.\nSAGE는 symbolic 저장소를 byte크기로 다음과 같이 인코딩하여 mapping한다.\nx=x'+256*x', where x=t, x'=subtag (t,0), x''=subtag(t,1) 3.4 Constraint Optimization Standard Optimization SAGE의 constraint generation의 속도와 메모리 사용을 향상시키기 위하여 몇가지 최적화 기법을 사용한다.\n1. Tag Caching : 구조적으로 동등한 tag들이 동일한 physical object에 mapping되도록 한다. 2. unrelated constraint elimination : 부정된 constraint와 symbolic variable을 공유하지 않는 constraint를 제거함으로서 constraint solver의 크기를 줄인다. 3. local constraint caching : 이미 path constraint에 추가된 constraint는 건너 뛴다. 4. flip count limit : 특정 명령어에서 생성된 constraint가 몇번 flip가능한 최대 횟수를 설정한다. 5. concretization : 여러 명령을 포함하는 symbolic tag를 concerete value로 줄인다. 이러한 최적화는 dynamical test generation에서 표준적인 방법이다. 이 섹션의 나머지 부분은 structured-file parsing application에 대한 최적화에사용되는 constraint subsumption(가정)에 대해서 설명한다.\nConstraint subsumption constraint subsumption은 주어진 분기 명령에서 셍성된 constraint를 추적하여 새로운 constaint f가 생성될때 SAGE는 빠른 syntactic check를 통하여 f 다른 constaint를 함축하거나 같은 명령에서 생성된 다른 constraint에 의해 함축되는지 판단하고 함축된다면 path constraint에서 제거된다.\nsubsumption 최적화는 다양한 image parser및 미디어 플레이어와 같은 structured file을 처리하는 많은 프로그램에 중요한 영향을 미친다.\nConstant Folding 다음과 같은 예제를 확인해보자\n1 2 3 mov cl, byte [...] dec cl # Decrement cl ja 2 # Jump if cl \u0026gt; 0 이 코드는 cl에 바이트를 로드하고 0이 될때까지 loop에서 감소시킨다. mov 명령에 의해 읽힌 바이트가 symbolic tag t0에 매핑된다고 하자. 3.3절에서 설명한 알고리즘은 다음과 t1\u0026gt;0,\u0026hellip;,tk-1\u0026gt;0과 tk\u0026lt;=0을 생성한다. 여기서 k는 로드된 바이트의 구체적인 값이고 ti+1=ti-1이다.\n반복마다 새로운 constraint와 symbolic tag를 생성하기 때문에 메모리는 루프 반복횟수에 선형적이다.\n여기서 subsumption을 사용한다면 첫 k-2개의 constraint는 다음 constraint에 의해 축약되기 때문에 제거할 수 있다. 우리는 symbolic tag는 선형적인 수로 유지해야 한다. 왜냐하면 각 tag는 이전 tag에 대한 조건으로 정의되기 때문이다.\n이를 상수 크기의 공간으로 동작을 하기 위해서는 tag 생성중 constand folding을 수행해야한다. : (t-c)-1=t-(c+1)\nconstraint subsumption과 constant folding을 적용한다면 다음 두가지 constraint를 갖는 path constraint가 된다.\nt0-(k-1)\u0026gt;0 and t0 -k \u0026lt;=0 sequence tag simplification 만약 multi-byte에 대해서는 또 다른 문제가 있다 다음 예제를 보자 위 예시와 비슷하지만 cl이 아닌 cx로 대체되었다.\n1 2 3 mov cx, word [...] dec cx # Decrement cx ja 2 # Jump if cx \u0026gt; 0 mov 명령에 의해 읽힌 두 바이트가 t'0 ,t\u0026rsquo;\u0026lsquo;0에 메핑된다고 가정한다면 다음과같은 constraint를 생성한다\ns1\u0026gt;0,...,sk-1\u0026gt;0 and sk\u0026lt;=0 where si+1 = \u0026lt;t'0,t''0\u0026gt;-1 이때 constant folding은 어려워진다. 왜냐하면 각 루프 반복은 syntatically unique하지만 의미적으로는 중복되는 word-size sequence tag이기 때문이다.\nSAGE는 sequence tag simplification을 지원한다. \u0026lt;subtag(t,0), subtag(t,1)\u0026gt;를 t로 재작성하여 동등한 tag를 피하고 constant folding을 지원한다.\nconstraint subsumption, constant folding, sequence tag simplification은 위에서 생성된 constraint를 상수공간에서 재생하는것을 보장해 준다.\n이 세가지 방법은 SAGE가 structured-file-parsing application을 효과적으로 fuzzing하도록 한다.\n4. Experiments Sblackbox fuzz에서 놓친 버그를 SAGE가 찾아낸것을 걸명한다. 두 memdia parsing application에서 SAGE의 행동에 대한 더 체계적인 연구룰 추구한다.\ninitial inpuy file의 중요성 generational search vs DFS block coverage heuristic의 효과 4.1 Initial Experiences MS07-017 MS는 ANI(애니메이션 커서 파일)을 parsing하는 코드에서 중요한 보안 패치를 발표했다. 이 코드에 대한 광범위한 blackbox fuzz testing을 하였지만 버그를 발견하지 못하였고 기존 static analysis 도구들은 과도한 거짓 false positive 없이 버그를 찾을 수 없었다. 하지만 SAGE는 well-formed ANI file에서 시작하여 몇시간 내에 버그를 드러내는 새로운 input file을 만들어 내었다.\n이 취약점은 ANI parsing code와 관련된 MS05-006에 대한 불완전한 패치로 인하여 생성되었다. 이 버그의 근본 원인은 ANI파일의 anih rdcord 에서 읽은 size parameter에 대한 검증을 못한 것이다. 이 패치는 첫번째 anih record만 확인하였고 파일에 36byte이하의 초기 anih record가 있으면 이후 모든 anih record에 대한 아이콘 로딩 함수가 호출된다. 두번째 이후 recode의 길이가 확인되지 않으므로 memory corruption이 발생할 수 있다.\ntestcase는 최소한 두개의 anih record가 필요하다. blackbox fuzz testing이 MS07-017을 발견하지 못한 이유는 testing에 사용된 모든 seed file이 하나의 anih record만을 가지고 있기 때문이다. 물론 blackvox fuzz testing을 위해 여러 testcase를 생성하는 grammar를 사용할 수 있지만 노력이 필요하고 ANI format을 넘어 일반화할 수 없다.\n반면 SAGE는 ANI format에 대한 지식 없이 하나의 anih record를 가진 well-formed ANI 파일에서 시작하여 MS07-017을 생성하는 입력을 생성할 수 있다. seed file은 잘성성된 ANI 파일 라이브러리에서 임의로 생성되었으며 user32.dll을 호출하여 ANI 파일을 parsing하는 작은 test driver을 사용하였다. 아래는 crash test case이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 SEED RIFF...ACONLIST B...INFOINAM.... 3D Blue Alternat e v1.1..IART.... ................ 1996..anih$...$. ................ ................ ..rate.......... ..........seq .. ................ ..LIST....framic on......... .. CRASH RIFF...ACONB B...INFOINAM.... 3D Blue Alternat e v1.1..IART.... ................ 1996..anih$...$. ................ ................ ..rate.......... ..........seq .. ................ ..anih....framic on......... .. Compressed File Format SAGE의 alpha 버전을 이용하여 압축 파일 형식을 처리하는 코드에서 버그를 찾도록 하였다. 이 parsing code는 blackbox fuzzing tool을 이용하여 테스트 되었지만 SAGE는 다음 두가지 새로운 버그를 찾았다.\nStack Overflow CPU를 100% 사용하게 하는 무한루프 Media File Parsing SAGE를 널리 사용되는 4가지 media file format parser에 적용하였다. 이를 Media 1,2,3,4라 하자. SAGE는 100개의 0x00으로 시작한 seed를 이용하여 각 Media File에서 충돌을 발견하여 9개의 bug reports를 생성하였다.\nOffice 2007 Application SAGE는 Office 2007의 large application에 대한 crash test case를 생성했다. 이는 NULL포인터 역참조 오류들이다. 이는 SAGE가 large scale의 프로그램에 대해서 성공적임을 보여준다.\nImage Parsing SAGE를 이용하여 media player의 image parsing code를 테스팅하였다. 초기에 충돌을 찾지 못하였지만 내부 도구를 사용하여 SAGE-generated test case를 추적하여 여러 uninitialized value use error를 발견하였다. 이 결과를 재현 가능한 충돌로 확장 가능하였다. 즉 SAGE는 즉시 충돌로 이어지지 않는 심각한 버그를 발견할 수 있었다.\n4.2 Experiment Setup Test Plan 널리 사용되는 Media 1,2 parser에 초점을 맞추었다. Media 1 parser에 대해 test media file liabrary에서 선택된 5개의 well-formed media file로 SAGE를 실행하였다. Media file은 다음과 같은 5개의 \u0026ldquo;bogus\u0026rdquo; 파일로실행하였다.\nbogus contents 1 \\x00 * 100 2 \\x00 * 800 3 \\x00 * 25600 4 rand * 100 5 rand * 100 이 10개의 파일에 대하여 10시간씩 SAGE를 실행하였다. 충돌을 찾은 경우 bloc coverage heuristic을 비활성화하고 다시 10시간 실행하였다.\n각 SAGE serach는 heap memory error을 확인하기위하여 AppVerfier를 사용하였다. error가 발생할때마다 AppVerfier는 테스트중인 application에서 crash를 발생시킨다. 이후 crashing test case, seed input에 의해 cover된 block의 수, 검색 과정에 추가된 code block의 수를 수집하였다.\nTriage SAGE는 동일한 버그를 나타내는 많은 test case를 생성할 수 있으므로 crashing file 을 stack hash를 이용하여 \u0026ldquo;bucket\u0026quot;하였다. 이는 오류 발생 명령의 주소를 포함며 동일한 원인으로 인해 다양한 경로로 발생한 버그에 대해서 같은 버그인지 분류하는 역할을 수행한다.\nNondeterminism in Coverage Results 실험의 일부로 test 실행중 cover된 block의 수를 측정하였다. 동일한 초기 프로그램에서 동일한 실행을 하더라도 약간의 다른 initial coverage가 나올 수 있다는것을 관찰하였다. 이는 test application을 사용하는 DLL을 로드하고 초기화하는 과정에서 발생하는 nondeterminisim 때문이라고 생각한다.\n4.3 Results and Observations 부록에는 실험 결과의 표가 있다. 여기서 우리는 몇가지 일반적인 관찰사항에 대해서 설명한다. 이러한 관찰사항은 두개의 application에 대한 제한된 샘플 크기에서 얻어진것이므로 주의해서 받아들여야 한다.\nSymbolic execution is slow 각 검색에서 symbolic execution에 소요된 시간을 측정하였다. symbolic excution에 소요되는 시간이 프로그램 testing이나 tracing 하는것보다 훨씬 더 많이 걸린린다. 예를들어 Media2 검색에서 wtf-3로 실행된 symbolic execution의 평균 실행 시간은 25분 30초이고 testing에 소요된 시간은 몇초이다. 왜냐하면 각 작업은 많은 test case를 생성하였기 때문이다. 하지만 전체 실행 시간은 25%에 불과하다 generational search가 symbolic execution을 효율적으로 활용함을 보여준다.\nGenerational search is better than depth-first search DFS를 사용하여 execution 하였을때 pathological divergence이 발생하였다. 이것은 path constraint의 AND 연산자를 구체화 하는것에 의해 발생하였다.\ncoverage와 관련하여도 geneartional search에 비해서 더 적은 것을 확인할 수 있었다. DFS가 localized하기 때문이다.반면 generational search의 경우 모든 depth에서 실행 분기를 탐색하여 프로그램의 레이어를 동시에 탐색한다.\nDFS가 symbolic execution에 더 많은 시간을 소비한다.\nDivergences are common 기본적인 test 설정에서 divergence를 측정하지 않았고 몇가지 측정용 test case를 실행하여 diveergence rate를 측정하여따 종종 60%넘기도 하였다. 이는 실험 설정에서 효율성을 위하여 non-linear operation (곱셈 나눗셈, 비트연산)을 구체화 하기 때문일 수 있다. 또한 아직 emulate하지 않은 x86 명령들이 존재하며 pointer의 dereference 에 대한 모델을 만들지 않았기 때문이다.\nsymbolic variable을 tracking하는것은 불완전할 수 있읏고 위에 언급한 snondeterministic한 요소를 제어하기 때문이다.\n그럼에도 SAGE의 검색 기술이 divergence를 허용함을 확인할 수 있었다.\nBogus files find few bugs 우리는 well-formed, bogus seed에서 발생한 crash data를 수집하였다. 각 시드 파일로 발견된 버그는 stack hash에 따라 나타내었다. 이 결과를 살펴보면 well-formed 파일을 initial로 하여야 fuzz testing이 잘 된다는 전통적인 지혜가 whitebox fuzzing에도 적용됨을 확인할 수 있었다.\nDifferent files find different bugs Media 1,2의 경우 bug를 찾은 well-formed file이 하나가 아니라는 것을 확인할 수 있었다. 각 search가 불완전 하기에 많은 well-formed file을 사용하는것이 중요하다.\nBugs found are shallow 각 seed file에 대하여 최대한 많은 generation을 수집하였다. 그런 다음 충돌이 발생한 버킷중 가장 마지막으로 찾은 generation을 확인하였다. media 1의 경우 4 generation 이내에 모든 버그를 찾았고 최대 generation은 5~7까지 다양하다.\n즉 이러한 검색에서 찾은 대부분의 버그는 shallow하다. 적은 수의 generation에 도달할 수 있다. 이는 작은 generation에서도 확장할 후보 입력이 많고 나중 세대의 많은 테스트의 coverage score가 낮기 때문이다.\nNo clear correlation between coverage and crashes coverage 증가가 새로운 버그관련과 관련이 있지만 모든 경우에 일관되게 관찰되지는 않았다.\nEffect of block coverage heuristic 다음 child를 선택하기위하여 block coverage heuristic을 사용을 한 테스트와 사용하지 않은 실행을 비교해본 결과 사용한 경우가 훨씬 많은 block을 추가함을 확인할 수 있었다.\n5. Other Relate Work Input Grammar 최근 fuzz testing에 있어서 많은 개발이 있었다. 하지만 이들은 대부분 가능한 input을 표현하기위한 grammar를 사용하였다. 또한 input을 생성할때 확률적 가중치를 할당하여 random test input generation을 위한 heuristic으로 사용할 수 있다. 이러한 가중치는 가벼운 동적 프로그래밍 계측을 사용하여 수집된 coverage data를 사용하여 자동의로 정의되거나 수정될 수 있다. 이러한 grammar또한 입력 검증 코드에서 흔히 발생하는 함정을 테스트 하기위한 규칙 (긴 문자열 ,NULL값 포함)을 포함 할 수 있다.\ninput grammar의 사용은 application-specific knowledge를 사용하고 다른 영역에 비해 특정 input space의 영역을 선호하는 test guideline을 만드는 것을 가능하게 한다. 순수 무작위 테스팅을 통하여 버그를 찾는 확률은 매우 작기 때문에 blackbox fuzzing을 가능하게 하는데 핵심적인 역할을한다. 하지만 grammar를 수동으로 작성하는것은 비용이 많이들고 확장성이 떨어진다.\n하지만 SEGA는 input grammar가 필요 없다. 하지만 주어진 search를 위한 initial seed file을 중요하게 생각한다. 이러한 seed file은 blackbox fuzzing에 사용되는 grammar를 사용하여 생성된다.\n또한 blackbox fuzz가 symbolic execution과 constraint solving의 비용 때문에 whitebox fuzz보다 더 빠른 속도로 새로운 테스트 케이스를 실행한다. 그리고 whitebox fuzzing의 symbolic executinon의 부정확성 때문에 whitebox fuzzing에서 발견하지 못한 새로운 path를 찾을 수 있다.\nGenerational Search Algorithm 이 논문의 접근 방식은 dynamic test generation 작업에 기반을 두고 있다. 주요 차이점은 heuristic을 사용하는 generational serach algorithm을 사용하고 large application을 테스트 한다는 것이다. trace-based x86-binary symbolic excution에 의해 가능하다. 이러한 차이점으로 dynamical test generation 보다 더 많은 버그를 발견할 수 있었다.\nSAGE은 dynamic taint analysis를 사용하는 도구와도 다르다. 이러한 도구는 false positive 가 발생할 수 있지만 symbolic execution은 static analysis의 핵심 구성 요소이다.\nstatic analysis 일반적으로 dynamic analysis보다 효율적이지만 정확도가 떨어지면 이둘은 상호보완적이다. static test generation은 특정 프로그램 경로를 따라가기위해 input vlaue를 계산하려고 시도하지만 프로그램을 실제로 실행하진 않는다. 반면 dynamic test generation은 추가적인 runtime information이 있기에 더 일반적이고 강력하다.\n6. Conclusion 우리는 dynamic test generation을 위한 새로운 탐색 알고리즘인 generational serach 를 도입하였다. 이 알고리즘은 divergences를 허용하고 비용이 많이드는 symbolic execution 을 더 잘 사용한다.\nSAGE는 이 알고리즘을 통하여 Windows에서 실행되는 다양한 x86코드에서 버글르 찾아내었다.\nSAGE의 행동을 잘 이해하기위한 실험에 있어서 well-formed input file을 사용하는것이 버그를 찾는것에 있어서 중요하다는걸 발견하였다.\n또한 탐색된 세대의 수가 block coverage보다 중요하다는 것을 알게되엇다. 특히 발견된 대부분의 버그들은 낮은 세대에서 발견되었다.\n이러한 결과는 제한된 크기의 셈플에서 나온것이므로 신중하게 다루어야 하지만 새로운 탐색 전략을 제시한다.\n정해진 시간동안 실행하는 대신 초기 seed file에서 작은 수의 세대를 탐색하고 이 test case가 소진되면 새로운 seed file로 넘어갈 수 있다.\n이러한 전략은 발견한 버그의 다른 경로를 찾는 \u0026ldquo;tail\u0026quot;을 잘라내고 같은 시간에 더 많은 고유한 버그를 찾을 수 있을지도 모른다.\n향후 연구에서 이 탐색 방법을 실행하여 우리의 block-coverage hueristic을 다른 seed file에 적용하여 동일한 코드를 여러번 탐색하는것을 피해야 한다.\n중요한 부분은 code coverage만 사용할때보다 depth와 code coverage의 좋바이 더 나은 지표인지 확인해야 한다.\n7. 의문점 후속 연구 소스코드를 볼 수 있을까? 유망한 (workList 상단) test case가 꼭 input을 bug를 trigger할 가능성이 높은 input일까? score봐야할지도? ","permalink":"https://246p.github.io/blog/paper_2/","summary":"Automated Whitebox Fuzz Testing\n0. Abstract fuzz testing은 소프트웨어 보안 취약점을 찾는 효과적인 기술이다. 전통적인 fuzzer들은 well-formed input에 random mutations을 적용하고 결과값을 테스트한다. 이 논문에서는 Symbolic execution과 Dynamic test generation을 적용하여 alternative whitebox fuzz testing을 구현하였다.\n이 논문에서는 well-formed input에 따라 실제로 실행되는 것을 기록하고, symbolicaly evalution하고, 프로그램이 입력을 어떻게 사용하는지 확인하여 입력에 대한 제약조건을 수집한다. 수집한 제약조건들을 하나씩 부정하고 constraint solver를 이용하여 solve한다. 이를 통해 프로그램에서 다른 경로를 실행하는 새로운 input을 생성한다.","title":"2. Automated Whitebox Fuzz Testing"},{"content":"All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution\n0. Abstract Dynamic taint analysis \u0026amp; forward Symbolic execution을 이용하여 다음과 같은 일을 많이 수행함\n1. Input Filter Generation 2. Test case generation 3. Vulnerabiliry discovery 이와 관련하여 이 논문은 두가지 파트로 되어있음\n1. dynamic taint analysis와 forward symbolic execution을 수행할 수 있는 general language 제시 2. 이를 구현함에 있어서 important implementation choices, common pitfalls, considerations 1. Introduction Dynamic analysis Dynamic analysis는 actual excution에 대한 추론을 가능하게함 한번에 하나의 실행에 대해서 고려함 다음 두가지 사항이 일반적으로 사용됨\n1. dynamic taint analysis - 미리 정의된 taint sources (ex user input)가 미치는 영향을 관찰함 2. forward symbolic execution - logical formula를 자동으로 형성하여 논리 축약을 실행함 이 두가지 분석은 다음과 같이 함께 사용되기도 한다.\nUnkown Vulnerability Detection 알려지지 않은 취약점을 탐지한다, code injection을 막을 수 있다.\nAutomatic Input Filter Generation 입력에서 exploite을 탐지하고 제거하는 Input Filter를 자동으로 생성하는데 사용된다.\nMalware Analysis Malware Binary를 통하여 정보가 어떻게 이동하는지 확인할 수 있다.\nTest Case Generation 프로그램을 테스트 하기 위한 입력을 자동으로 생성하는데 사용된다.\n이를 실제로 구현화는 과정속에서 여러 한계점, 구현 요령, 타협점을 찾게 된다. 따라서 이 논문은 다음과 같은 내용을 소개한다.\n1. Dynamic taint Analysis 와 forward symbolic exceution을 공식화한다. 2. 공식화한 내용을 바탕으로 implementation details, caveats, and choices 를 설명한다. 2. A General Language Overview dynamic taint analysis과 forward symbolilc execution은 는 특정 언어에 대해서 정의되어왔다.\n이 논문에서 SimpIL (Simple Intermediate Language)을 제시하고 있다.\n이 언어는 다양한 프로그래밍 언어에 대한 컴파일러에서 사용하는 내부 표현을 표현할 수 있다.\n이 언어는 numbered statements로 이루어져 있고 assignments, assertions, jumps, conditional jump로 이루어져 있다. 또한 get_input을 통하여 사용자의 입력을 받을 수 있다. 또한 32-bit정수에 대해서만 교려한다. 이를 확장하는것은 간단하다.\nOperational Semantics Operation semantics는 해당 언어로 작성된 프로그램을 어떻게 실행할지 엄밀하게 정의한다. 이를 통하여 실행을 기반으로 정의되는 dynamic program analyses를 정의하는 방법이 된다.\n프로그램을 실행할때 패턴 매칭을 통하여 statement에 맞는 applicable rule을 찾는다.\nLanguage Discussion 이 언어는 Dynamic taint analysis와 forward symbolic execution을 보이기 위하여 디자인 되었기 때문에 function, scope에 대한 구현을 하지 않았다. 이러한 생략은 다음과 같은 두가지 접근방법으로 간단하게 추가할 수 있다.\n1. high-level 언어를 SimpIL로 컴파일 함수, 버퍼에 대한 추상화는 BAP, BitBlaze와 같은 도구를 이용하여 가능하다. 이전 다른 연구를 통하여 이를 증명하였다.\n2. higher-level constructs를 SimpIL에 추가 예를들어 Call, RET 명령을 추가하여 직접 function을 지원할 수 있다.\n3. Dynamic Taint Analysis Dynamic taint analysis는 sources(input)와 sinks(중요한곳) 사이의 흐름을 추적하는 것이다. taint source에서 파상된 데이터에 의존하는 모든 값은 taint되었다고 간주한다.\ntaint policy는 taint된 값이 실행중에 어떻게 이동하는지, 어떤 종류의 작업이 taint를 도입하는지, taint된 값에 대한 어떤 검사를 수행하는지를 의미한다.\n이는 taint analysis application에 따라 다르다. 하지만 원론적인 concepts는 같다.\n이와 관련하여 두가지 오류가 존재한다.\n1. Oveertainted - 값이 taint source에서 파생되지 않음에도 오염된것으로 판단함 2. Undertainted - taint된 값임에도 불구하고 이를 탐지하지 못함 이 두 오류를 줄여야 한다.\nDynamic Taint Analysis Sematntics 각 프로그램의 taint된 상태를 확인하기 위하여 우리의 언어의 값들을 다음과 같이 튜플 \u0026lt;v,τ\u0026gt; 로 재 정의한다. v는 기존 언어에서 의미하는 값이고 τ는 taint되어 있는지를 의미한다.\n아래와 같이 taint analysis policy를 확인한다.\nDynamic Taint Policies taint policty는 3가지 성질을 지정한다.\n1. 새로운 taint의 도입 2. taint의 전파 3. taint의 확인 Taint Introduction 일반적으로 모든 변수, 메모리의 값이 초기화될때 taint되지 않았다고 가정한다.\nSimpIL에서 get_input이라는 하나의 input source만 가지고 있다.\n하지만 실제 구현에서 여러가지 input source를 가지고 있다. 일반적으로 input source들을 구분한다. 예를들어 인터넷을 통해 들어오는 네트워크 입력은 taint를 도입할 수 있지만 신뢰할수 있는 파일에서 읽는 정보는 그렇지 않다.\n특정 taint source를 독립적으로 추적할 수 있다.\nTaint Propagation taint policy는 기존 데이터에섯 파생된 데이터의 오염상태를 지정한다. 예를 들어 t_1 or t_2는 t_1 또는 t_2가 taint 되어있을때 결과가 taint 되어있음을 의미한다.\nTaint Checking 값이 taint되었는지 확인하기 위하여 taint checking을 수행한다. 예를들어 P_gotocheck(t)는 해당 주소가 taint된 값을 가질때 jump를 수행하는것이 안전하면 T를 반환한다. 만약 F가 반환되면 프로그램이 비정상적으로 종료된다.\nA Typical Taint Policy 아래와 같은 typical attack detection policy를 tainted jump policy라고 한다.\ntainted jump policy는 control flow hijacking 공격을 방어하기 위함이다.\n주요 아이디어는 입력에서 파생된 값이 return address나 function pointer을 덮어쓰지 않게 한다. 즉 jump에 대한 안정성을 보장하는 것이다.\n이 를 구현하기 위하여 get_input에 의해 반환된 모든 값에 taint를 도입한다. 이후 taint된 값이 이항 연산등을 통하여 프로그램으로 직접적으로 퍼지게 된다.\nDifferent Policies for Different Applications 응용프로그램에 맞게 taint policy를 정해야 한다. 특히 Table III에 설명된 typical taint policy는 메모리 주소 오염에 대한 고려를 하지 못한다.\nDynamic Taint Analysis Challenges and Opportunities dynamic taint analysis와 관련하여 고려할 사항들이 있다.\nTainted Addresses 메모리 연산은 메모리 셀의 주소와 해당 셀에 저장된 값이 관여한다.\nTable III의 tainted jump policy는 이를 독립적으로 추적한다.\n예를들어 다음과 같은 프로그램을 생각해보자.\n1 2 3 x := get_input(·) y := load(z+x) goto y 이와같은 코드는 모든 메모리 주소에 접근할 수 있다.\n기존 tainted jump policy는 이를 탑지하지 못할 수 있다. 이를 해결하기 위하여 tainted address policy를 사용할 수 있다.\n물론 이와같이 확장할경우 overtaint의 위혐이 있다. 즉 jump에 대한 검사의 undertaint와 address에 대한 검사의 overtaint를 잘 조절해야한다.\nControl-flow taint control-flow를 통하여 data flow가 변할 수 있다. 이를 고려하지 않으면 taint를 결정할 수 업시게 전체 분석이 undertaint될 수 있다. 불행히 순수한 dynamical taint analysis를 통해서는 contro-flow taint를 계산할 수 없다. 왜냐하면 단일 execution에서는 하나의 path만 실행되기 때문이다.\n이 문제를 해결하기 위해선 다음과 같은 해결방법이 있다.\n1. static analysis 사용 - static analysis를 통하여 control-flow를 계산할 수 있다. 2. heuristics 사용 - heuristics을 사용하여 상황에따라 overtaitn, undertaint할지 결정한다. Sanitization Dynamic taint analysis는 taint를 추가 한다. (제거하지 않는다) 이는 프로그램이 실행될때 계속 더 많은 값이 taint 되는 taint spread 문제를 발생시킨다.\ntaint analysis에서는 값에서 taint를 제거하는것 또한 중요하다. 예를 들어서 b = a ^ a 는 b를 0으로 초기화 되는 의미이지만 taint하다고 판단할 수 있다. 이를 방지하여야 한다.\nTime of Detection vs Time of Attack taint가 전파되는 시간과 그 taint가 발생하는 시간과의 차이가 존재한다.\n4. Forward Symbolic Execution Forward Symbolic Execution은 다양한 입력에 따라 프로그램의 동작을 한번에 추론할 수 있도록 한다.\nApplications and Advantages Multiple Input\n한번에 여러 입력에 대해 분석할 수 있다.\nSemantics of Forward Symbolic Execution 일반 실행과 Forward Symbolic Execution의 차이점은 get_input()의 결과가 구체적인 값 대신 기호를 반환한다. 기호를 포함하는 표현식은 구체적인 값으로 평가될 수 없다. SimpIL언어를 Table VI와 같이 확장된다.\nForward Symbolic Execution Challenges and Opportunities Symbolic Memory Addresses 메모리에서 값을 저장하거나 불러올때 참조되는 주소가 구체적인 값이 아닌 사용자 입력에 파생된 표현식(기호)일때 발생하는 문제이다.\n실제 프로그램에서도 사용자 입력에 따라 달라지는 테이블 조회 등 여러 형태로 빈번하게 발생하는 문제이다.\nSymbolic Memory Addresses는 Single path에 대한 execution에서도 aliasing issues를 발생할 수 있다. 두 값이 동일한 주소를 참조할때 발생한다.\n이를 해결하기위하여 메모리를 참조할때 두가지 방법이 사용된다\n1. Symbolic Memory Address를 제거하기 위하여 건전하지 않는 가정을 한다. 이 논문에서는 코드를 변형하였다. 2. SMT Solver에서 이를 수행하도록 한다. 3. 두 값이 동일한 주소를 가르키고 있는지 추론하기위하여 alias analysis를 수행한다. Path Selection 경로가 분기될때 어떠한 분기를 먼저 탐색할지 결정해야 한다. Smmbolic Execution을 수행할때 이를 tree로 생각할 수 있다. 분석은 tree의 root node에서 시작하여 fork가 발생할때 child node를 생성한다. 이때 다음 탐색할 node를 결정하는 것은 중요하다 왜냐하면 무한 루프에 빠질 수 있기 때문이다.\n이와 같은 \u0026ldquo;stuck\u0026quot;인 상황을 회피하기 위하여 다음과 같은 방법을 사용할 수 있다.\nDepth-First-Search 탐색시 maximum depth를 설정하여 무한 루프를 방지한다.\nConcolic Testing Concolic Testing은 구체적인 실행을 사용하여 프로그램 실행을 추적하는 것이다. Forward Symbolic Execution과 동일한 경로를 따르지만 조건을 선택하고 해당 조건문을 부정하여 다른 경로로 강제할 구체적 입력을 생성할 수 있다.\nRandom Paths random하게 탐색을 할 경우 더 낮은 상태에 대해 더 높은 가중치를 부여하여 stuck을 방지할 수 있다.\nHeuristics 아직 다루지 않은 코드에 도달할 가능성이 높은 상태에 더 많은 가중치를 준다. 실행되지 않은 명령어까지의 거리 등을 변수로 한다.\nSymbolic Jumps GOTO 규칙은 LOAD및 STORE와 비슷하다. 하지만 Forward Symbolic Execution에서는 Jump target이 구체적인 위치가 아닌 표현식 일 수 있다. 이와같은 문제를 Symblic jump problem 이라고 한다.\n이 문제는 많은 연구에서 직접적으로 다루지 않고 있다. 다음은 Symblic jump을 다루는 3가지 방법이다.\nUse Concolic analysis Concolic analysis를 사용하여 간접적으로 jump targets을 확인한다. concrete execution 에서 점프 대상이 확인되면 이를 symbolic execution에 적용하는 것이다.\n단점은 알려진 jump targets만 탐색하기 때문에 프로그램의 전체를 탐색하기는 더 어려워진다.\nUse SMT solver SMT solver를 이용하여 변수에 대한 값 할당(구체적인 점프 대상)을 얻고 이 값을 부정하는 합집합을 다시 SMT solver에 요청한다. 효육적이지 못하다.\nUse Static analysis 정적분석을 사용하여 전체 프로그램에 대한 추론과 가능한 jump target을 찾을 수 있다. Binary-level jump static analyses는 해당 식에서 참조될 수 있는 값들에 대해 추론할 수 있다.\nHandling System and Library Calls C 언어의 read와 같은 함수로 interupt가 발생할 수 있다. 이때 read가 새로운 기호 입력을 반환하게 하게 한다.\nconcolic 기반으로 접근한다면 간단하다는 장점을 갖고 있다.\n구현하기 쉽고 프로그램이 환경과 상호작용하는 문제를 우회한다. 반면 완벅한 분석을 제공하지 않는다. 왜냐하면 일부 호출은 동일한 입력을 받더라도 같은 결과를 반환하지 않기 때문이다.\nPerformance 이 방법의 효율성에 대해서 생각해보면\n1. exponential number of program branches 2. exponential number of formulas 3. exponentially sized formula per branch 각 분기지점에서 fork가 발생하기 때문에 expontential 하게 늘어난다. 이를 해결하기 위하여 다음과 같은 방법이 사용된다\n더 좋은 하드웨어 사용 치환으로 expotential하지 않게 변형 formula의 중복을 제거 subformula에 대한 정보를 cache에 저장하여 재사용 weakest precondition 사용 Mixed Execution 실제로 사용되는 프로그램의 유형에 따라 symbolic input을 특정 형식의 입력으로 제한할 수 있다.\n일부 입력은 구체적으로 허용하고 일부 입력을 기호적으로 허용한 것을 mixed execution이라고 한다.\n이는 구체적인 값에 관한 계산을 프로세서에서 수행할 수 있도록 한다. 즉 사용자 입력에 의존하지 않는 부분은 concrete execution의 속도로 실행할 수 있다.\n5. Related Work Formalization and Systematization Dynamic Security mechanisms은 새로운것은 아니지만 이전 연구들은 dynamic taint analysis와 forward symbolic execution을 형식화 하지 않았다.\n이 논문은 프로그래밍 언어를 정의하여 의미론적 모호성을 해소하였다.\nApplications Automatic Test-case Generation Automatic Filter Generation Automatic Network Protocol Understanding Malware Analysis Web Applications Taint Performance \u0026amp; Frameworks Extensions to Taint Analysis ","permalink":"https://246p.github.io/blog/paper_1/","summary":"All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution\n0. Abstract Dynamic taint analysis \u0026amp; forward Symbolic execution을 이용하여 다음과 같은 일을 많이 수행함\n1. Input Filter Generation 2. Test case generation 3. Vulnerabiliry discovery 이와 관련하여 이 논문은 두가지 파트로 되어있음\n1. dynamic taint analysis와 forward symbolic execution을 수행할 수 있는 general language 제시 2. 이를 구현함에 있어서 important implementation choices, common pitfalls, considerations 1.","title":"1. All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution"},{"content":"4. 함수 정의와 호출 앞에서 선언한 언어를 확장하여 함수를 정의한다.\n4.1 문법구조 프로그램에서 함수를 사용하려면 함수 생성(선언)과 호출을 지원해야한다.\nE -\u0026gt; n | E1 + E2 | E1 - E2 | E1 * E2 | E1 / E2 | x | let x = E1 in E2 | if E1 then E2 else E3 | iszero E | fun x E 함수 생성식 | E1 E2 함수 호출식 fun x E x를 인자로 받아서 E의 계산 결과를 반환하는 함수를 정의하는 구문이다.\nx를 형식인자, E를 몸통식 이라고 한다.\nex) fun x (x+1) : 인자 x를 받아서 x+1을 반환하는 함수\nE1 E2 E1은 호출할 함수를 계산하는 식이고 E2는 함수의 인자를 계산하는 식이다. E2의 값을 실제인자라고 부른다.\nex) let f = fun x (x+1) in (f 2)\n함수 fun x (x+1)을 f라고 정의하고 실제인자 2를 이용하여 호출하는 식이다.\n동치관계 우리는 다음과 같은 동치관계를 발견할 수 있다.\nlet x = E1 in E2 ≡ (fun x E2) E1\n4.2 의미구조 함수의 생성과 호출에서 실행 의미를 정의해보자 이에 앞서 자유변수에 대하여 정의할 필요가 있따.\n4.2.0 자유변수 함수의 의미를 정의하기우ㅏㅎ여 변수들을 자유변수와 묶인변수로 구분해야한다.\n자유변수란 주어진 식에서 그 정의를 찾을 수 없는 변수를 말한다.\n묶인변수란 주어진 식에서 정의를 찾을 수 있는 변수를 의미한다.\n또한 식E에 등장하는 자유변수의 집합 FV(E)는 다음과 같이 귀납적으로 정의된다.\n묶인변수는 VAR(E)\\FV(E)가 된다.\nFV(n) = ∅ FV(x) = {x} FV(E1 + E2) = FV (E1) ∪ FV(E2) FV(let x = E1 in E2) = FV(E1) ∪ (FV(E2) \\ {x}) FV(if E1 then E2 else E3) = FV(E1) ∪ FV(E2) ∪ FV(E3) FV(fun x E) = FV(E) \\ {x} FV(E1 E2) = FV(E1) ∪ FV(E2) 4.2.1 유효범위 먼저 다음 함수에 대해서 생각해보자\nlet x = 1 in let f = fun y (x+y) in let x = 2 in let g = fun y (x+y) in (f 1) + (g 1) 함수에서 등장하는 자유변수의 값을 결정할때 다음 두가지 방법을 생각해볼 수 있다\n함수가 정의되는 시점 (정적 유효범위) f가 정의되는 시점에서 x=1, g가 정의되는 시점에서 x=2이므로 다음과 같이 계산된다.\nf 1 = 2, g 1 = 3\n함수가 호출되는 시점 (동적 유효범위) f, g가 호출되는 시점에서 x=2이므로 다음과 같이 계산된다.\nf 1 = 3, g 1 = 3\n대부분의 프로그래밍 언어는 정적 유효범위를 지원한다. 변수의 유효범위가 프로그래밍 실행전에 정적으로 결정되어 프로그램을 이해하기 쉬워지기 때문이다.\n4.2.2 정적 유효범위 정적 유효범위를 지원하도록 함수의 의미를 정의해보자. 먼저 함수를 값으로 사용할 수 있도록 하기위하여 다음과 같이 의미공간을 확장한다.\nVal = Z + Bool + Procedure Procedure = Var × Exp × Env Env = Var → Val 함수 생성식의 실행 의미는 다음과 같이 정의할 수 있다.\n------------------------ ρ ⊢ fun x E ⇒ (x, E, ρ) 즉 환경 ρ에서 식 fun x E를 계산하면 함수값 (x,E,ρ)가 생성된다.\n함수 호출식은 다음과 같다.\nρ ⊢ E1 ⇒ (x, E, ρ′) ρ ⊢ E2 ⇒ v {x |→ v}ρ′ ⊢ E ⇒ v′ --------------------------------------------------------- ρ ⊢ E1 E2 ⇒ v′ 4.2.3 동적 유효범위 동적 유효범위를 지원하기위해 다음과같이 함수호출식의 의미를 변경하면 된다.\nρ ⊢ E1 ⇒ (x, E, ρ′) ρ ⊢ E2 ⇒ v {x |→ v}ρ ⊢ E ⇒ v′ --------------------------------------------------------- ρ ⊢ E1 E2 ⇒ v′ 함수 몸통부를 계산할때 ρ′ 대신 ρ를 사용한다 즉 위에서 정의한 의미공간의 Env를 제외하여 Procedure = Var × Exp과 같이 다시 정의할 수 있다.\n이를 다시 정의하여 나타내면 다음과 같다.\n--------------------- ρ ⊢ fun x E ⇒ (x, E) ρ ⊢ E1 ⇒ (x, E) ρ ⊢ E2 ⇒ v {x |→ v}ρ ⊢ E ⇒ v′ ------------------------------------------------------ ρ ⊢ E1 E2 ⇒ v′ 4.2.4 재귀함수 정적 유효범위 재귀함수 정적 유효범위를 지원하는 의미구조 하에서 다음과 같은 프로그램을 생각해보자.\nlet f = fun x (f x) in (f 1) 위 식을 실행하면 다음과 같은 환경이 만들어진다.\n{f |→ (x, (f x), ∅)} 이 환경에서 f 1을 실행한다면 몸통 식 f x를 계산할때 f에 대한 정보가 없으로 실행이 불가능하다. 즉 문법구조를 확장하여 재귀함수를 지원하도록 해야한다.\nE -\u0026gt; ... | let rec f(x) = E1 in E2 또한 의미구조 정의를 위하여 다음과 같이 의미공간을 확장한다.\nVal = Z + Bool + Procedure + RecProcedure Procedure = Var × Exp × Env RecProcedure = Var × Var × Exp × Env Env = Var → Val 즉 재귀함수는 일반함수와 다르게 함수 이름을 기억한다. 재귀함수 생성식의 의미는 다음과 같다.\n{f |→ (f, x, E1, ρ)}ρ ⊢ E2 ⇒ v ------------------------------- ρ ⊢ letrec f(x) = E1 in E2 ⇒ v ρ ⊢ E1 ⇒ (f, x, E, ρ′) ρ ⊢ E2 ⇒ v {x |→ v, f |→ (f, x, E,ρ′)}ρ′ ⊢ E ⇒ v′ ------------------------------------------------------------------------------- ρ ⊢ E1 E2 ⇒ v 비재귀 함수의 호출과 다르게 함수를 호출할때 함수가 정의된 시점의 환경과 호출되는 함수를 함께 확장한다.\n동적 유효범위 재귀함수 동적 유효범위에서는 다른 확장 없이 재귀함수가 잘 정의된다.\n왜냐하면 함수의 몸통을 함수의 호출이 일어날때 환경에서 계산한느데 그때 환경에 이미 함수 f에 대한 정보가 존재하기 때문이다.\n","permalink":"https://246p.github.io/blog/pl_4/","summary":"4. 함수 정의와 호출 앞에서 선언한 언어를 확장하여 함수를 정의한다.\n4.1 문법구조 프로그램에서 함수를 사용하려면 함수 생성(선언)과 호출을 지원해야한다.\nE -\u0026gt; n | E1 + E2 | E1 - E2 | E1 * E2 | E1 / E2 | x | let x = E1 in E2 | if E1 then E2 else E3 | iszero E | fun x E 함수 생성식 | E1 E2 함수 호출식 fun x E x를 인자로 받아서 E의 계산 결과를 반환하는 함수를 정의하는 구문이다.","title":"4. 함수 정의와 호출"},{"content":"3. 변수와 환경 3.1 문법구조 우리가 1장에서 선언한 정수형 언어를 다음과 같이 확장한다.\nE -\u0026gt; n | E1 + E2 | E1 - E2 | E1 * E2 | E1 / E2 | x 변수 | let x = E1 in E2 let식 | if E1 then E2 else E3 조건식 | iszero E bool식 x 먼저 프로그램에서 식이 올 수 있는 위치에 변수 x를 사용할 수 있도록 하였다.\nlet x = E1 in E2 변수 x를 선언하는 식이다. E1의 값을 x라고 한 후 E2를 계산한다. 변수 x를 사용할 수 있는 유효범위는 E2이다.\nif E1 then E2 else E3 조건식이다. E1을 계산하면 참 또는 거짓이 나와야 한다.\nE1이 참이라면 E2를, 거짓이라면 E3를 계산한다.\nizero E 조건문에서 E1을 연산하기 위하여 도입된 식으로 true또는 false를 계산한다.\n3.2 의미구조 이제 언어의 의미구조를 정하여 위의 언어를 실행하는 규칙을 만들어주자\n3.2.0 표기법 합집합 X + Y\n차집합 X \\ Y\n곱집합 X × Y (cartesian product)\n3.2.1 환경 프로그램이 변수를 포함하게 된다면 변수의 현재 값을 알려주는 장치인 환경이 필요하다. 예를들어 x+y는 x와 y가 현재 어떤 값을 갖는지에 따라 달라진다.\nx=1, y=2인 환경 {x |→ 1, y |→ 2}\nx=2, y=3인 환경 {x |→ 2, y |→ 3}\nx+y는 두 환경에서 값이 변경된다\n즉 환경은 변수에서 값으로 가는 유한 함수이다.\nEnv = Var -\u0026gt; Val\n가능한 모든 환경을 Env, 프로그램에서 사용가능한 변수의 집합을 Var로 표기하였다.\nVal은 프로그램이 다루는 값들의 집합을 의미한다 현재 언어에서 값은 정수와 T/F를 다루고 있으므로 Val은 다음과 같이 정의할 수 있다.\nVal= Z + B\n이와같이 프로그램의 의미를 정의하기 위해 필요한 집합의 모임 (Env, Var, Val)을 의미공간이라고 한다.\n환경에 대한 표기법은 다음과 같다.\n환경을 나타낼때 ρ를 사용한다 (ρ∈Env) {x1 |→ v1, . . . , xk |→ vk}는 x1,\u0026hellip;,xk가 v1,\u0026hellip;,yk로 매핑되어있는 환경이다. 환경ρ에서 변수 x가 의미하는 값은 ρ(x)로 표기한다. 아무 변수도 정의되어 있지 않은 환경은 빈 환경은 ∅로 표기한다. {x |→ v}ρ는 주어진 환경 ρ에서 x=v 추가하여 확장한 환경을 의미한다. 3.2.2 추론규칙 환경 ρ에서 식 E를 계산한 값은 v이다를 다음과 같이 표현한다\nρ ⊢ E ⇒ v\n예를들어 ∅ ⊢ 1 ⇒ 1, {x |→ 1} ⊢ x+1 ⇒ 2 이다.\n이와 같은 의미구조를 정의하는 추론규칙은 다음과 같다.\n---------- E-Num ρ ⊢ n ⇒ n ρ ⊢ E1 ⇒ n1 ρ ⊢ E2 ⇒ n2 --------------------------- E-Plus ρ ⊢ E1 + E2 ⇒ n1 + n2 ρ ⊢ E1 ⇒ n1 ρ ⊢ E2 ⇒ n2 --------------------------- E-Minus ρ ⊢ E1 - E2 ⇒ n1 − n2 ρ ⊢ E1 ⇒ n1 ρ ⊢ E2 ⇒ n2 --------------------------- E-Mult ρ ⊢ E1 * E2 ⇒ n1 ∗ n2 ρ ⊢ E1 ⇒ n1 ρ ⊢ E2 ⇒ n2 --------------------------- n2!=0 E-Div ρ ⊢ E1 / E2 ⇒ n1/n2 ------------- E-Var ρ ⊢ x ⇒ ρ(x) ρ ⊢ E1 ⇒ v1 {x |→ v1}ρ ⊢ E2 ⇒ v ----------------------------------- E-Let ρ ⊢ let x = E1 in E2 ⇒ v E-Let ρ ⊢ E1 ⇒ true ρ ⊢ E2 ⇒ v ------------------------------- E-If-T ρ ⊢ if E1 then E2 else E3 ⇒ v ρ ⊢ E1 ⇒ false ρ ⊢ E3 ⇒ v ------------------------------- E-If-F ρ ⊢ if E1 then E2 else E3 ⇒ v ρ ⊢ E ⇒ 0 --------------------- E-Zero-T ρ ⊢ iszero E ⇒ true ρ ⊢ E ⇒ n --------------------- n!=0 E-Zero-F ρ ⊢ iszero E ⇒ false ","permalink":"https://246p.github.io/blog/pl_3/","summary":"3. 변수와 환경 3.1 문법구조 우리가 1장에서 선언한 정수형 언어를 다음과 같이 확장한다.\nE -\u0026gt; n | E1 + E2 | E1 - E2 | E1 * E2 | E1 / E2 | x 변수 | let x = E1 in E2 let식 | if E1 then E2 else E3 조건식 | iszero E bool식 x 먼저 프로그램에서 식이 올 수 있는 위치에 변수 x를 사용할 수 있도록 하였다.\nlet x = E1 in E2 변수 x를 선언하는 식이다.","title":"3. 변수와 환경"},{"content":"1.귀납법 1.1 집합의 귀납적 정의 귀납법을 이용하여 집합을 정의할 수 있다.\nS를 다음을 만족하는 가장 \u0026lsquo;작은\u0026rsquo; 자연수 집합으로 정의해보자\n0 ∈ S n ∈ S ⇒ n + 3 ∈ S {0,1,2,3,4,\u0026hellip;} 도 만족하지만 {0,3,6,9,\u0026hellip;}가 가장 작은 집합이다.\n추론 규칙 추론 규칙을 이용한다면 다음과 같이 정의할 수 있다.\nn ∈ S ------- ---------- 0 ∈ S (n + 3) ∈ S 추론규칙을 CFG를 이용하여 표현하기도 한다.\nn → 0 | n + 3 1.2 프로그래밍 언어의 귀납적 정의 문법구조 +, -, *, / 을 지원하는 정수식 언어는 다음과 같은 추론규칙을 통해 귀납적으로 정의할 수 있다.\nE1 E2 E1 E2 E1 E2 E1 E2 - ----- ----- ----- ----- n E1-E2 E1+E2 E1*E2 E1/E2 보통 이와같은 방법보다는 다음과 같은 방법으로 표현한다.\nE -\u0026gt; n | E1 + E2 | E1 - E2 | E1 * E2 | E1 / E2 예를들어 정수식 1+(2*(3-4))는 다음과 같이 표현할 수 있다.\n- - 3 4 --- 2 3-4 ------- 1 2*(3-4) ----------- 1+(2*(3-4)) 의미구조 \u0026ldquo;정수식 E를 계산하면 정수 n을 갖는다\u0026quot;를 다음과 같이 표현한다.\nE ⇒ n 이를 이용하여 우리의 문법을 표현하면 다음과 같다.\n------ E-Num n ⇒ n E1 ⇒ n1 E2 ⇒ n2 ------------------ E-Plus E1 + E2 ⇒ n1 + n2 E1 ⇒ n1 E2 ⇒ n2 ------------------ E-Minus E1 - E2 ⇒ n1 - n2 E1 ⇒ n1 E2 ⇒ n2 ------------------ E-Mult E1 * E2 ⇒ n1 * n2 E1 ⇒ n1 E2 ⇒ n2 ------------------ n2!=0 E-Div E1 / E2 ⇒ n1 / n2 1.3 귀납적 증명 귀납적으로 정의된 집합의 원소들이 가지는 성질을 증명하는데 사용되는 증명방법이다.\n집합S에 속한 모든 원소 x에 대해서 어떤 성질이 성립합을 보이기 위하여 아래 두가지를 보인다.\nx가 S의 기초원소이면 P(x)를 직접 보인다. x가 S에 속하는 다른 원소 y_i를 이용하여 귀납적으로 정의된다면 P(y_i)가 모두 사실이라 가정한 후 이를 이용하여 P(x)를 증명하면 된다. ","permalink":"https://246p.github.io/blog/pl_1/","summary":"1.귀납법 1.1 집합의 귀납적 정의 귀납법을 이용하여 집합을 정의할 수 있다.\nS를 다음을 만족하는 가장 \u0026lsquo;작은\u0026rsquo; 자연수 집합으로 정의해보자\n0 ∈ S n ∈ S ⇒ n + 3 ∈ S {0,1,2,3,4,\u0026hellip;} 도 만족하지만 {0,3,6,9,\u0026hellip;}가 가장 작은 집합이다.\n추론 규칙 추론 규칙을 이용한다면 다음과 같이 정의할 수 있다.\nn ∈ S ------- ---------- 0 ∈ S (n + 3) ∈ S 추론규칙을 CFG를 이용하여 표현하기도 한다.\nn → 0 | n + 3 1.","title":"1. 귀납법"},{"content":" ","permalink":"https://246p.github.io/blog/fsharp_2/","summary":" ","title":"Fsharp_2"},{"content":"F#이란? ","permalink":"https://246p.github.io/blog/fsharp_1/","summary":"F#이란? ","title":"1"},{"content":"Bug and Vulnerability Bug : error in program that make it malfunction Vulunerability : bug that causes security issues Buffer Overflow \u0026amp; Memory Corruption C has no automatic check on array boundary\nAllow writing past the end of an array Buffer OverFlow corrupt other variables and data in memory Setuid Bit (SUID) Linux 환경에서 passwd 명령을 입력하면 /etc/passwd 에 저장된 정보를 변경한다.\n/만약 /etc/passwd 명령어가\n","permalink":"https://246p.github.io/blog/hacking_2/","summary":"Bug and Vulnerability Bug : error in program that make it malfunction Vulunerability : bug that causes security issues Buffer Overflow \u0026amp; Memory Corruption C has no automatic check on array boundary\nAllow writing past the end of an array Buffer OverFlow corrupt other variables and data in memory Setuid Bit (SUID) Linux 환경에서 passwd 명령을 입력하면 /etc/passwd 에 저장된 정보를 변경한다.\n/만약 /etc/passwd 명령어가","title":"2. Introduction to Software Vulnerability"},{"content":"CIA Properties Key properties that we want to achieve for security\nConfidentiality: secrets must be kept secret Integrity: data should not be tampered Availability: the system must be usable Common Types of Attacks Denai of service Shutting down system or service runnig on it ex) Blue Screen, 503 Error Code execution Running arbitary, unintended code Privilege escalation Gaining unintended privileges Information Leakage Accessing sensetive data ex) Hartblled bug ","permalink":"https://246p.github.io/blog/hacking_1/","summary":"CIA Properties Key properties that we want to achieve for security\nConfidentiality: secrets must be kept secret Integrity: data should not be tampered Availability: the system must be usable Common Types of Attacks Denai of service Shutting down system or service runnig on it ex) Blue Screen, 503 Error Code execution Running arbitary, unintended code Privilege escalation Gaining unintended privileges Information Leakage Accessing sensetive data ex) Hartblled bug ","title":"1. Overview"},{"content":"Bottom-up bottom-up parsing을 수행할때는 소괄호를 지원하는 조금 다른 CFG를 사용한다\n피 연산자로 id만 지원함 left-recursion이 있어도 됨 Top-down parsing은 다음과 같은 방식으로 시작된다.\ntree를 만드는 동안 token을 하나씩 읽는다. 끝이 난다면 root node는 start symbol이 된다. 다음은 id1 * id2 에 대한 예시이다. 즉 reversed order Rightmost Derivation이라고 볼 수 있다.\nLR(1) Parsing 매 단계마다 다음 token을 받아올지 production rule을 적용할지 정해야 한다. top-down parsing과 동일하게 parsing table을 사용한다. Three Types of LR(1) Parsing Left-to-right, Rightmost derivation, 1 token lookahead SLR(1) Parsing : Simple LR(1) Parsing 우리가 다룰것 LALR(1) Parsing : Look-Ahead LR(1) Parsing SLR(1)보다 많은 grammar에 적용 가능하다. 많은 언어에서 사용된다. Canonical LR(1) Parsing LALR(1)보다 더 많은 grammar에 적용 가능하다. 복잡하다. LR(1) Grammar 위에서 소개한 CFG는 SLR(1)에 포함된다. LR(1) Parsing Overview LR(1) Parsing을 하기 위해서 두가지 작업을 수행한다.\nshift : input token을 Stack에 push 한다. reduce : Stack의 top에 있는 변수를 rule에 맞게 변형한다. 다음은 id1 * id2 에 대한 예시이다.\nStack Input Tokens id1 * id2 $ id1 *id2 $ F *id2 $ T *id2 $ T* id2 $ T*id2 $ \u0026hellip; \u0026hellip; E $ LR(1) Parsing 하지만 실제 LR(1) Parsing은 매우 복잡하게 작동한다.\n효율성을 위하여 state를 저장하는 Stack을 추가로 구현한다.\n또한 LR(1)의 parsing table은 LL(1)과 다르다\nRow : top element in the state stack Column : next token or reduced variable SLR(1) Parsing Table\n추가로 CFG의 Rule을 새롭게 정의한다.\nCFG R1 E -\u0026gt; E + T R2 E -\u0026gt; T R3 T -\u0026gt; T * F R4 F -\u0026gt; (E) R5 F -\u0026gt; id Shift action : s5\ns5 : shift a symbol and push state 5 Reduce action : r6\nreduce with rule 6 and pop state lookup table [0,F]=g3, push state 3 State Stack Symbol Stack Input Tokens Action 0 id1 * id2 $ 0 5 id1 * id2 $ s5 0 3 F * id2 $ r6 0 2 T * id2 $ r4 0 1 E id2 $ r2 0 1 6 E + $ s6 0 1 6 5 E + id2 $ s5 0 1 6 3 E + F $ r6 0 1 6 9 E + T $ r4 0 1 E $ r1 SLR Parsing Table Preparation with CFG add new start symbol (R0) S -\u0026gt; E\nLR(0) ","permalink":"https://246p.github.io/blog/compiler_3_2/","summary":"Bottom-up bottom-up parsing을 수행할때는 소괄호를 지원하는 조금 다른 CFG를 사용한다\n피 연산자로 id만 지원함 left-recursion이 있어도 됨 Top-down parsing은 다음과 같은 방식으로 시작된다.\ntree를 만드는 동안 token을 하나씩 읽는다. 끝이 난다면 root node는 start symbol이 된다. 다음은 id1 * id2 에 대한 예시이다. 즉 reversed order Rightmost Derivation이라고 볼 수 있다.\nLR(1) Parsing 매 단계마다 다음 token을 받아올지 production rule을 적용할지 정해야 한다. top-down parsing과 동일하게 parsing table을 사용한다. Three Types of LR(1) Parsing Left-to-right, Rightmost derivation, 1 token lookahead SLR(1) Parsing : Simple LR(1) Parsing 우리가 다룰것 LALR(1) Parsing : Look-Ahead LR(1) Parsing SLR(1)보다 많은 grammar에 적용 가능하다.","title":"3. Syntax analysis (2)"},{"content":"Context-free grammar CFG : defined with a set of production rules ex) E -\u0026gt; E + E E -\u0026gt; E * E E -\u0026gt; id E -\u0026gt; num\nDerivation ex) E ⇒ E + E ⇒ id + E ⇒ id + num we will use ⇒* to denote arbitrary number of rewriting steps\nTerminal Symbol vs Non-Terminal Symbol Terminal Symbol : can\u0026rsquo;t be rewritten anymore (+, *, id, num) Non-Terminal Symbol : can be rewritten (E)\nCFG : Sentence and Language Sentence : Result of derivation that does not contain nay non-terminal\nLanguage : set of all derivable sentences\n𝑳(𝑮) = {𝒘 | 𝑺⇒ ∗𝒘, 𝒘 consists of terminals}\nLeftmost Derivation derivation을 할때 가장 왼쪽의 non-terminal을 먼저 변환하는 규칙\nParse tree Derivation process중 Parse tree를 만들 수 있음\nex) E ⇒ E + E ⇒ id + E ⇒ id + num\nRegEx vs CFG R = ((id | num) (\u0026rsquo; + \u0026rsquo; | \u0026rsquo; * \u0026lsquo;))* (id | num) 와 같이 RegEx로 할 수 있다. 하지만 brackets : \u0026ldquo;{}\u0026rdquo;, \u0026ldquo;{{}}\u0026rdquo;, {{{}}}\u0026quot;,\u0026hellip; 과 같이 RegEx로 표현 불가능한 것이 존재 한다. 또한 RegEx는 Parse Tree를 생성할 수 없다. Ambiguous Grammar derivations 방법에 따라서 서도 다른 parse tree가 만들어진다.\n이와 같은 경우를 막기 위하여 세가지 요소를 고려해야한다.\nEliminate ambiguity (Precedence) Bind * before + id + id * id must be interpreted as id + (id * id) (Associativity) * and + associate to the left id + id + id must be interpreted as (id + id) + id 다음과 같이 CFG를 정의하면 가능하다.\nStart variable is E\nE -\u0026gt; E + T | T\nT -\u0026gt; T * F | F\nF -\u0026gt; id | num\nGeneral Rewriting Algorithm? ambiguous -\u0026gt; unambiguous로 rewrite하는 algorithm은 없다.\n심지어 ambiguous 한지 판단하는 algorithm 또한 없다.\nUndecidable problem 하지만 우리는 unambiguous 하다는 가정하에 진행한다. Top-down parsing Parser는 derivation을 추론해야함 (if exist)\nParsing is the process of inferring derivation for the token stream construction of parse tree Top-down parsing leftmost derivations root node에서 아래 방향으로 늘려야함 At each step, we must rewrite the left most non-terminal\n이때 어떠한 production rule을 사용할지 골라야 한다. parsing table : case에 따라 어떤 rule을 사용할지 알려줌\ncurrent status + next token을 통해 고를 수 있음 table drivven LL(1) parsing or LL(1) parsing Left-to-right, Leftmost derivation, 1 token lookahead LL(1) Grammar LL(1) Grammar 란 LL(1) parsing이 적용 되는 CFG를 의미한다. 모든 CFG에 대해서 적용할 수 는 없다. 즉 어떤 grammar들은 parsing table을 만들 수 없음 다음 CFG는 LL(1)이 아님 E -\u0026gt; E + T | T T -\u0026gt; T * F | F F -\u0026gt; id | num\nLeft-Recursion CFG has a variable A that appear as the fist symbol in right-hand side of a rule\n위 예시에서 E, T는 left-recursive 이다.\nCFG가 left-recursive이면 LL(1)이 될 수 없다.\nEliminating Left-Recursion 𝑨 → 𝑨𝜶 | 𝜷\n위와 같은 rule을 다음과 rewrite할 수 있다.\n𝑨 → 𝜷𝑨′\n𝑨′ → 𝜶𝑨′ | 𝝐 이를 우리의 production rule에 적용해 보자.\nLeft- Recursion 이 아니더라도 꼭 LL(1) Grammer는 아니다. 다행히 운이 좋게도 우리의 CFG는 LL(1) Grammar이다.\nLL(1) Parsing Example num + id 에 대해서 LL(1) parsing을 적용해보자\nStack Input Tokens Rule E $ num + id $ T E\u0026rsquo; $ num + id $ E -\u0026gt; T E\u0026rsquo; F T\u0026rsquo; E\u0026rsquo; $ num + id $ T -\u0026gt; F T' num T\u0026rsquo; E\u0026rsquo; $ num + id $ F -\u0026gt; num T\u0026rsquo; E\u0026rsquo; $ + id $ Match and Pop E\u0026rsquo; $ + id $ T\u0026rsquo; -\u0026gt; 𝜺 + T E\u0026rsquo; $ + id $ E\u0026rsquo; -\u0026gt; + T E; T E\u0026rsquo; $ id $ Match and Pop F T\u0026rsquo; E\u0026rsquo; $ id $ T -\u0026gt; F T' id T\u0026rsquo; E\u0026rsquo; $ id $ F -\u0026gt; id T\u0026rsquo; E\u0026rsquo; $ $ Match and Pop E\u0026rsquo; $ $ T\u0026rsquo; -\u0026gt; 𝜺 $ $ E\u0026rsquo; -\u0026gt; 𝜺 Parsing Table Parsing 을 수행하다보면 Parsing table의 필요성을 느끼게 된다.\nRow : non-terminal on stack top\nColumn : first terminal (token) in buffer\nFirst and Follow Parsing table을 만들기 위해서는 First, Follow set을 먼저 만들어야 한다.\nFirst(a) : a를 파생하여 나올 수 있는 문장 중 첫 문자들의 집합\nFollow(X) : X를 파생하여 나온 문장 문장 이후 나올 수 있는 문자 들의 집합\n다음은 예시이다. Building Parsing Table X -\u0026gt; a 에 대해서 parsing table에 넣는 방법이다.\nfor t in First (a), add X -\u0026gt; a to the parsing table in Tap [X, t] if 𝜺 is in First (a), for t in Follow (x), add X -\u0026gt; a to Tap [X, t] Construction Fail X -\u0026gt; a1 | \u0026hellip; | an 을 생각해 보자\nFirst (ai)들이 disjoint 하지 않을 경우 table의 하나의 slot에 여러 rule이 들어가게 된다. 즉 해당 parsing table을 만들 수 없고 CFG가 LL(1) Grammar가 아니라는 의미이다.\n","permalink":"https://246p.github.io/blog/compiler_3_1/","summary":"Context-free grammar CFG : defined with a set of production rules ex) E -\u0026gt; E + E E -\u0026gt; E * E E -\u0026gt; id E -\u0026gt; num\nDerivation ex) E ⇒ E + E ⇒ id + E ⇒ id + num we will use ⇒* to denote arbitrary number of rewriting steps\nTerminal Symbol vs Non-Terminal Symbol Terminal Symbol : can\u0026rsquo;t be rewritten anymore (+, *, id, num) Non-Terminal Symbol : can be rewritten (E)","title":"3. Syntax analysis (1)"},{"content":"Token 문자열을 해당 문자열의 의미하는 연산, 값에 따라 token으로 분류할 수 있다.\nToken Example Keyword int, void, if Identifier a, var_1 Integer 10, 20 Operators +, =, * Whitespace “ “, \\t, \\n Regula Expression Token을 나누는 방법은 Automata를 이용한다. 이에 앞서 Regula Expression (RegEx) 에 대해서 알아볼 필요가 있다.\nRegEx는 Base case와 Inductive case로 구성된다.\nRegula language 𝚺 를 이용하여 symbol들의 집합을 표기한다. ex) binary numbers : 𝚺 = {\u0026lsquo;0\u0026rsquo;,\u0026lsquo;1\u0026rsquo;}, lowercase letters : 𝚺 = {\u0026lsquo;a\u0026rsquo;,\u0026lsquo;b\u0026rsquo;,\u0026hellip;\u0026lsquo;z\u0026rsquo;}\nWord는 주어진 𝚺의 symbol들의 나열이다. empty word를 나타낼때에는 𝜖을 사용한다. ex) 𝚺 = {\u0026lsquo;0\u0026rsquo;,\u0026lsquo;1\u0026rsquo;,\u0026lsquo;2\u0026rsquo;} -\u0026gt; word : 𝜖, \u0026ldquo;1,\u0026rdquo; ,\u0026ldquo;12\u0026rdquo;, \u0026ldquo;012\u0026rdquo;\nLanguage란 word의 집합을 의미한다. L1 = {\u0026ldquo;a\u0026rdquo;,\u0026ldquo;b\u0026rdquo;,\u0026ldquo;ab\u0026rdquo;,\u0026ldquo;aaaab\u0026rdquo;,\u0026hellip;} Base case 빈 문자는 𝜖로 표기한다. 하나의 문자는 \u0026lsquo;c\u0026rsquo; ∈ 𝚺 로 표기한다. Inductive case Union : R1|R2 : R1 or R2 Concat : R1∙R2 : R1 and R2 Repeat : R* : R을 반복 우선순위는 * \u0026gt; ∙ \u0026gt; | 순이다. ex){ 𝝐, \u0026ldquo;a\u0026rdquo;, \u0026ldquo;aa\u0026rdquo;, \u0026ldquo;aaa\u0026rdquo;, \u0026hellip;, \u0026ldquo;b\u0026rdquo;, \u0026ldquo;bb\u0026rdquo;, \u0026ldquo;bbb\u0026rdquo;, \u0026hellip; }\nFormal Definition of RegEx L(R) : a set defined by R\nDefining Token RegEx를 이용하여 Token을 정의할 수 있다.\ndigit = | \u0026lsquo;0\u0026rsquo; | \u0026lsquo;1\u0026rsquo; | \u0026lsquo;2\u0026rsquo; | \u0026lsquo;3\u0026rsquo; | \u0026lsquo;4\u0026rsquo; | \u0026lsquo;5\u0026rsquo; | \u0026lsquo;6\u0026rsquo; | \u0026lsquo;7\u0026rsquo; | \u0026lsquo;8\u0026rsquo; | \u0026lsquo;9\u0026rsquo;\nletter_ = [ \u0026lsquo;A\u0026rsquo;-\u0026lsquo;Z\u0026rsquo; ] | [ \u0026lsquo;a\u0026rsquo;-\u0026lsquo;z\u0026rsquo; ] | \u0026lsquo;_\u0026rsquo;\nKeyword = \u0026ldquo;int\u0026rdquo; | \u0026ldquo;void\u0026rdquo; | \u0026ldquo;if\u0026rdquo; | \u0026ldquo;else\u0026rdquo; | \u0026hellip;\nInteger = digit\nIdentifier = letter_ ( letter_ | digit )*\nOperator = \u0026ldquo;=\u0026rdquo; | \u0026ldquo;+\u0026rdquo; | \u0026ldquo;-\u0026rdquo; | \u0026hellip;\nWhitespaces = (\u0026quot; \u0026quot; | \u0026ldquo;\\t\u0026rdquo; | \u0026ldquo;\\n\u0026rdquo;)+\nAutomata Finite-state Automata는 NFA, DFA 두 종류가 있다.\nNon-deterministic finite automata (NFA) Initial state, Accepting state가 존재하며 각 state들은 𝜖 또는 𝚺 에 따라 변화한다.\n다음 state로 가는 Outgoing edges들이 같은 symbol을 공유할 수 있다.\nNFA 를 이용하여 RegEx R = (\u0026lsquo;a\u0026rsquo;|\u0026lsquo;b\u0026rsquo;)* ∙ \u0026lsquo;a\u0026rsquo;를 구현해 보면 다음과 같다.\nDeterministic finite automata (DFA) initial state, Accepting state가 존재하며 각 state들은 𝚺에 따라 변화한다.\n다음 State로 가는 Outgoing edges들이 같은 symbol을 공유 할 수 없다.\n𝝐-closure 우리는 RegEx-\u0026gt;NFA-\u0026gt;DFA-\u0026gt;Code(Lexer) 순으로 변환하려고 한다.\n이를 위히 𝝐-closure 라는 개념을 도입한다.\n𝝐-closure(S) : S에서 symbol 없이 도달 할 수 있는 state의 집합 위 그림에서 𝝐-closure({s2,s5}) = {s2,s5,s6} 이다.\nNFA to DFA NFA를 DFA로 변환하기 위해선 NFA의 여러 state를 DFA의 하나의 state에 mapping 해야한다.\nNFA의 s0의 𝝐-closure 계산 𝝐-closure({s0})={s0,s1}, 이는 DFA의 starting state가 된다. S01에서 𝚺의 symbol들에 대해서 𝝐-closure 계산 \u0026lsquo;a\u0026rsquo; : 𝝐-closure({s2})={s2} \u0026lsquo;b\u0026rsquo; : 𝜙 이를 s2에서도 반복한다. \u0026lsquo;a\u0026rsquo; : 𝜙 \u0026lsquo;b\u0026rsquo; : 𝝐-closure({s2})={s1,s3} s13 에서도 반복한다. \u0026lsquo;a\u0026rsquo; : 𝜖-closure( {𝑠1,s3} ) = {𝑠2} \u0026lsquo;b\u0026rsquo; : 𝜙 탐색하지 않은 state가 없으므로 중단한다. accepting state는 NFA와 동일하다. Ambiguity 만약 int =x+10 이라는 문자열을 token으로 구분해 보자. 이때 int는 keyword, indentifier 둘다 해당할 수 있다.\n이러한 모호성을 해소하기 위해서는 각 keyword간에 precedence를 정해주어야 한다.\n","permalink":"https://246p.github.io/blog/compiler_2/","summary":"Token 문자열을 해당 문자열의 의미하는 연산, 값에 따라 token으로 분류할 수 있다.\nToken Example Keyword int, void, if Identifier a, var_1 Integer 10, 20 Operators +, =, * Whitespace “ “, \\t, \\n Regula Expression Token을 나누는 방법은 Automata를 이용한다. 이에 앞서 Regula Expression (RegEx) 에 대해서 알아볼 필요가 있다.\nRegEx는 Base case와 Inductive case로 구성된다.\nRegula language 𝚺 를 이용하여 symbol들의 집합을 표기한다. ex) binary numbers : 𝚺 = {\u0026lsquo;0\u0026rsquo;,\u0026lsquo;1\u0026rsquo;}, lowercase letters : 𝚺 = {\u0026lsquo;a\u0026rsquo;,\u0026lsquo;b\u0026rsquo;,\u0026hellip;\u0026lsquo;z\u0026rsquo;}","title":"2. Lexical Analysis"},{"content":"컴파일러란? 컴파일러는 source language를 target language로 변환한다.\n일반적으로 source = high-level, target = low-level 이다. ex) C -\u0026gt; machine code\nCompiler vs Interpreter Compiler는 input program을 executable form으로 변환한다.\n반면 Interpreter는 input program을 실행한다.\nCompier 컴파일러는 세가지 과정으로 구분할 수 있다.Front-end -\u0026gt; Middle-end -\u0026gt; Back-end\nFront-end Lexer (lexical analysis) 문자열을 token단위로 나눈다. x=y+10; -\u0026gt; VAR \u0026ldquo;X\u0026rdquo;, ASSIGN, VAR \u0026ldquo;y\u0026rdquo;, PLUS, CONST 10\nParser (syntax analysis) abstract syntax tree (AST)를 생성한다. Type Checker (semantic analysis) AST를 분석하여 type이 알맞은지 확인한다. IR Generator 로 이루어져 있다. AST를 IR로 변환한다. Middle-End 실행 시간, 코드 크기, 메모리 사용량 등을 고려하여 IR을 최적화한다.\nBack-End IR을 target language로 변환한다. 이때 Target-dependent optimization 이 일어난다\n","permalink":"https://246p.github.io/blog/compiler_1/","summary":"컴파일러란? 컴파일러는 source language를 target language로 변환한다.\n일반적으로 source = high-level, target = low-level 이다. ex) C -\u0026gt; machine code\nCompiler vs Interpreter Compiler는 input program을 executable form으로 변환한다.\n반면 Interpreter는 input program을 실행한다.\nCompier 컴파일러는 세가지 과정으로 구분할 수 있다.Front-end -\u0026gt; Middle-end -\u0026gt; Back-end\nFront-end Lexer (lexical analysis) 문자열을 token단위로 나눈다. x=y+10; -\u0026gt; VAR \u0026ldquo;X\u0026rdquo;, ASSIGN, VAR \u0026ldquo;y\u0026rdquo;, PLUS, CONST 10\nParser (syntax analysis) abstract syntax tree (AST)를 생성한다. Type Checker (semantic analysis) AST를 분석하여 type이 알맞은지 확인한다.","title":"1. overview"},{"content":"1. 소감 하루동안 \u0026ldquo;돌아는 가는\u0026rdquo; 웹사이트를 만들었다.\n웹에 대한 지식이 전무하기 때문에 많은 시행착오가 있었던것 같다.\ntruouble shooting 과정에서 Papermod 위키를 10번은 읽은것 같다.\n아직 다음과 같이 해결해야할 문제가 남아있다.\n2. 해결해야 하는 문제 prev/next가 뜻과 반대로 작용함\n다른 사람의 repository를 본 결과 theme의 자체적 문제일 가능성이 높아보임\nblog 제외한 menu 에서 prev/next 버튼이 없음\nmenu 시스템을 다시 한번 손봐야 할것 같음\n이미지 첨부 안됨\n가장 큰 문제인데 상대 경로를 통한 이미지 첨부가 안됨\n1 ![img](./../../themes/PaperMod/images/screenshot.png) 웹에서 받아오는건 됨\n1 ![img](https://i.pinimg.com/474x/4b/e5/f3/4be5f377959674df9c2fe172df272482.jpg) 3. 추가하고싶은 기능 댓글 기능 구현\nstatic site의 특성상 댓글이 기본 기능으로 없음, Utterance를 사용하면 구현할 수 있음\n방문자수 확인\nHits나 Google Analasys를 이용하여 구현할 수 있을것 같음, 난이도가 낮아보임\n","permalink":"https://246p.github.io/blog/hugo_4/","summary":"1. 소감 하루동안 \u0026ldquo;돌아는 가는\u0026rdquo; 웹사이트를 만들었다.\n웹에 대한 지식이 전무하기 때문에 많은 시행착오가 있었던것 같다.\ntruouble shooting 과정에서 Papermod 위키를 10번은 읽은것 같다.\n아직 다음과 같이 해결해야할 문제가 남아있다.\n2. 해결해야 하는 문제 prev/next가 뜻과 반대로 작용함\n다른 사람의 repository를 본 결과 theme의 자체적 문제일 가능성이 높아보임\nblog 제외한 menu 에서 prev/next 버튼이 없음\nmenu 시스템을 다시 한번 손봐야 할것 같음\n이미지 첨부 안됨\n가장 큰 문제인데 상대 경로를 통한 이미지 첨부가 안됨","title":"4. 중간 점검"},{"content":"1. hugo.yaml 사이트의 전반적인 설정을 저장하는 설정이다. 예시 코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 baseURL: \u0026#34;https://246p.github.io/\u0026#34; #기본주소 title: Junlog #이름 paginate: 5 theme: PaperMod enableRobotsTXT: true buildDrafts: false buildFuture: false buildExpired: false googleAnalytics: UA-123-45 minify: disableXML: true minifyOutput: true params: env: production # to enable google analytics, opengraph, twitter-cards and schema. title: Junlog description: \u0026#34;MJ\u0026#39;s Study Log\u0026#34; keywords: [Blog, Portfolio, PaperMod] author: Kim-Minjoon # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors images: [\u0026#34;\u0026lt;link or path of image for opengraph, twitter-cards\u0026gt;\u0026#34;] DateFormat: \u0026#34;January 2, 2006\u0026#34; defaultTheme: dark # dark, light disableThemeToggle: true sectionPagesMenu: true ShowReadingTime: false ShowShareButtons: false ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true ShowWordCount: false ShowRssButtonInSectionTermList: true UseHugoToc: true disableSpecial1stPost: false disableScrollToTop: false comments: false hidemeta: false hideSummary: false ShowToc: true TocOpen: true assets: # disableHLJS: true # to disable highlight.js #disableFingerprinting: true favicon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; favicon16x16: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; favicon32x32: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; apple_touch_icon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; safari_pinned_tab: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; label: text: \u0026#34;HOME\u0026#34; icon: /apple-touch-icon.png iconHeight: 35 profileMode: enabled: true title: \u0026#34;Hello World\u0026#34; # optional default will be site title subtitle: \u0026#34;Welcome to MJ`s Blog\u0026#34; imageUrl: \u0026#34;\u0026#34; # optional imageTitle: \u0026#34;\u0026#34; # optional imageWidth: 120 # custom size imageHeight: 120 # custom size socialIcons: - name: github url: \u0026#34;https://github.com/246p\u0026#34; - name: linkedin url: \u0026#34;https://www.linkedin.com/in/minjoon-kim-9823101a7/\u0026#34; - name: instagram url: \u0026#34;https://www.instagram.com/minjunkinn/\u0026#34; analytics: google: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; bing: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; yandex: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; cover: hidden: true # hide everywhere but not in structured data hiddenInList: true # hide on list pages and home hiddenInSingle: true # hide on single page fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;, \u0026#34;content\u0026#34;] menu: # 메뉴에서 이중 디렉토리는 불가능함 main: - identifier: POST name: POST url: /post/ weight: 10 - identifier: hacking name: hacking url: /hacking/ weight: 20 - identifier: blog name: blog url: /blog/ weight: 30 - identifier: CV name: CV url: https://docs.google.com/document/d/1ZByTPJ0BOfy14Zpwjisc0QT0JuTDOpcl/edit?usp=sharing\u0026amp;ouid=104987107477019496766\u0026amp;rtpof=true\u0026amp;sd=true weight: 40 pygmentsUseClasses: true markup: highlight: noClasses: false # anchorLineNos: true # codeFences: true # guessSyntax: true # lineNos: true # style: monokai 2. Page.md 게시물을 작성할때 페이지의 정보에 대한 설정이다. 예시코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 title: \u0026#34;1. Hugo 시작\u0026#34; date: 2024-01-06T18:12:26+09:00 #weight: 1 # aliases: [\u0026#34;/first\u0026#34;] tags: [\u0026#34;Hugo\u0026#34;, \u0026#34;Papermod\u0026#34;, Blog] author: \u0026#34;Kim-Minjoon\u0026#34; # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors showToc: true TocOpen: true draft: false # 글쓰기 아이콘 hidemeta: false # 시간, 작성자 등 comments: false #description: \u0026#34;부제목\u0026#34; #부재목 canonicalURL: \u0026#34;https://canonical.url/to/page\u0026#34; disableHLJS: false # to disable highlightjs disableShare: true # 아래 공유 관련 sns 메뉴 hideSummary: false #home에서 글 내용 안보이게 searchHidden: false #글 검색 허용 ShowReadingTime: false # 읽은 시간 ShowBreadCrumbs: true # Home \u0026gt;\u0026gt; posts 내용 ShowPostNavLinks: true ShowWordCount: false # 단어 수 ShowRssButtonInSectionTermList: true UseHugoToc: true cover: image: \u0026#34;\u0026lt;image path/url\u0026gt;\u0026#34; # image path/url alt: \u0026#34;\u0026lt;alt text\u0026gt;\u0026#34; # alt text caption: \u0026#34;\u0026lt;text\u0026gt;\u0026#34; # display caption under cover relative: false # when using page bundles set this to true hidden: true # only hide on current single page --- 3. default.md blog/archetypes/defaul.md 파일에 새로 생성되는 파일에 대한 기본 설정을 저장할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 --- title: \u0026#34;{{ replace .File.ContentBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} #weight: 1 # aliases: [\u0026#34;/first\u0026#34;] tags: [\u0026#34;Tag\u0026#34;] author: \u0026#34;Kim-Minjoon\u0026#34; # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors showToc: true TocOpen: true draft: false # 글쓰기 아이콘 hidemeta: false # 시간, 작성자 등 comments: false #description: \u0026#34;부제목\u0026#34; #부제목 canonicalURL: \u0026#34;https://canonical.url/to/page\u0026#34; disableHLJS: false # to disable highlightjs disableShare: true # 아래 공유 관련 sns 메뉴 hideSummary: false #home에서 글 내용 안보이게 searchHidden: false #글 검색 허용 ShowReadingTime: false # 읽은 시간 ShowBreadCrumbs: true # Home \u0026gt;\u0026gt; posts 내용 ShowPostNavLinks: true ShowWordCount: false # 단어 수 ShowRssButtonInSectionTermList: true UseHugoToc: true cover: image: \u0026#34;\u0026lt;image path/url\u0026gt;\u0026#34; # image path/url alt: \u0026#34;\u0026lt;alt text\u0026gt;\u0026#34; # alt text caption: \u0026#34;\u0026lt;text\u0026gt;\u0026#34; # display caption under cover relative: false # when using page bundles set this to true hidden: true # only hide on current single page --- ","permalink":"https://246p.github.io/blog/hugo_3/","summary":"1. hugo.yaml 사이트의 전반적인 설정을 저장하는 설정이다. 예시 코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 baseURL: \u0026#34;https://246p.","title":"3. Papermod 설정"},{"content":"0. Markdown이란 github에 들어가본 사람이라면 한번쯤 .md 확장자 파일을 본 적 있을 것이다. markdown은 간단한 문법으로 쉽게 쓰고 읽을 수 있다. 다음과 같은 장단점이 존재한다.\n장점\n간결하다 텍스트 에디터로 쉽게 작성 가능하다. 다양한 프로그램과 플랫폼에서 활용할 수 있다. 단점\n표준이 없다. 모든 HTML을 표기할 수 없다. 1. 문법 Header 다음과 같이 제목을 표기할 수 있다.\n1 2 3 # Header 1 ## Header 2 ### Header 3 Header 1 Header 2 Header 3 BlockQuote 1 2 3 \u0026gt;first \u0026gt; \u0026gt; second \u0026gt; \u0026gt; \u0026gt; third first\nsecond\nthird\nList 1 2 3 1. first 2. second 3. third first second third 순서를 바꾸어도 순서\u0026rsquo;만\u0026rsquo; 정렬된다.\n1 2 3 1. first 3. third 2. second first third second 순서없는 list (*, +, -) 1 2 3 * first * second * third first second third code 다음과 같이 코드 들여쓰기를 할 수 있다.\n1 2 3 ```c printf(\u0026#34;hello world\\n\u0026#34;); ``` 1 printf(\u0026#34;hello world\\n\u0026#34;); vertical bar 1 2 --- *** link 1 2 [Title](link) [Google](https://google.com) Google\n2. 사용되는곳 가볍고 많은곳에 사용된다는 점에 있어서 Github, Stack Overflow, Velog, Obsidian, Discord 등 개발자가 많이 사용하는 플렛폼에서 많이 사용된다.\n","permalink":"https://246p.github.io/blog/hugo_2/","summary":"0. Markdown이란 github에 들어가본 사람이라면 한번쯤 .md 확장자 파일을 본 적 있을 것이다. markdown은 간단한 문법으로 쉽게 쓰고 읽을 수 있다. 다음과 같은 장단점이 존재한다.\n장점\n간결하다 텍스트 에디터로 쉽게 작성 가능하다. 다양한 프로그램과 플랫폼에서 활용할 수 있다. 단점\n표준이 없다. 모든 HTML을 표기할 수 없다. 1. 문법 Header 다음과 같이 제목을 표기할 수 있다.\n1 2 3 # Header 1 ## Header 2 ### Header 3 Header 1 Header 2 Header 3 BlockQuote 1 2 3 \u0026gt;first \u0026gt; \u0026gt; second \u0026gt; \u0026gt; \u0026gt; third first","title":"2. MarkDown 문법"},{"content":"0. 들어가며 먼저 github.io를 이용하여 블로그를 구축하기위해서 SSG(Static Site Generator)를 정해야 한다. 대표적으로 Jkelly(Ruby), Eleventy(Node.js), Hugo(Go) 중 Hugo를 선택하였다. 한국어 레퍼런스가 부족하다는 단점이 있지만 속도측면에서 가장 빠르기 때문이다.\n이 글은 Mac 사용자를 기준으로 작성되었다.\n1. hugo 설치하기 먼저 home brew를 이용하여 hugo를 설치해야 한다.\n1 brew install hugo 만약 home brew가 설치되어 있지 않다면 다음 명령을 사용하자\n1 /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 2. github repository 만들기 hugo 를 이용하여 사이트를 제작하기 위해서는 repository 2개가 필요하다.\nblog : 사이트를 빌드 하기 위한 파일들을 저장한다.\n246p.github.io : 빌드된 사이트의 코드를 저장한다.\n3. 사이트 생성하기 1 hugo new site blog --format yaml 원하는 테마를 고른다 테마는 다음 사이트에서 확인할 수 있다.\n나는 마이너한 언어기도 하고 한글로 작성된 블로그가 잘 없어서 기술문서가 상세히 작성된 Papermod를 선택하였다. -WiKi\n테마를 적용한다.\n1 2 git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 echo \u0026#34;theme: Papermod\u0026#34; \u0026gt;\u0026gt; hugo.yaml 이제 로컬 환경에서 만들어진 사이트를 시험해본다.\n1 hugo server -D localhost:1313 에 접속하여 사이트가 작동되는지 확인할 수 있다.\n4. github에 업로드하기 다음은 사이트를 github와 연결해야한다.\n1 2 3 4 git init ID=$(git config --global user.name) git remote add origin https://github.com/$ID/blog.git git submodule add -b master --force https://github.com/$ID/$ID.github.io.git public 이제 빌드를 할 차례이다. 빌드는 앞으로 많이 사용할 예정이므로 스크립트를 작성해보자\n1 2 vi deploy.sh chmod 777 deploy.sh vim을 이용하여 다음 스크립트를 입력하자\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash echo -e \u0026#34;\\033[0;32mDeploying update to github...\\033[0m\u0026#34; hugo -t PaperMod cd public git add . msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push -u origin main cd .. git add . msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push -u origin main 다음 명령어를 실행하여 github에 업로드하자.\n1 ./deploy.sh 5. 게시물 만들기 새로운 게시물을 만들때 다음과 같은 명령으로 만들 수 있다.\n1 hugo new post/new_post.md ","permalink":"https://246p.github.io/blog/hugo_1/","summary":"0. 들어가며 먼저 github.io를 이용하여 블로그를 구축하기위해서 SSG(Static Site Generator)를 정해야 한다. 대표적으로 Jkelly(Ruby), Eleventy(Node.js), Hugo(Go) 중 Hugo를 선택하였다. 한국어 레퍼런스가 부족하다는 단점이 있지만 속도측면에서 가장 빠르기 때문이다.\n이 글은 Mac 사용자를 기준으로 작성되었다.\n1. hugo 설치하기 먼저 home brew를 이용하여 hugo를 설치해야 한다.\n1 brew install hugo 만약 home brew가 설치되어 있지 않다면 다음 명령을 사용하자\n1 /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 2. github repository 만들기 hugo 를 이용하여 사이트를 제작하기 위해서는 repository 2개가 필요하다.","title":"1. Hugo 시작"},{"content":"2학년 겨울 방학에 들어가기 앞서 나만의 공부 내용을 정리할만한 블로그를 만들어 보고싶다는 생각을 하게 되었다.\n개인 서버를 이용하여 웹사이트를 구축할까도 생각해보았지만 도메인 호스팅 비용, 서버유지관리 등 측면에서 github.io를 선택하게 되었다.\n앞으로 주 1회 이상 매주 공부한 내용을 포스팅할 예정이다.\n","permalink":"https://246p.github.io/blog/hugo_0/","summary":"2학년 겨울 방학에 들어가기 앞서 나만의 공부 내용을 정리할만한 블로그를 만들어 보고싶다는 생각을 하게 되었다.\n개인 서버를 이용하여 웹사이트를 구축할까도 생각해보았지만 도메인 호스팅 비용, 서버유지관리 등 측면에서 github.io를 선택하게 되었다.\n앞으로 주 1회 이상 매주 공부한 내용을 포스팅할 예정이다.","title":"블로그를 시작하면서"}]